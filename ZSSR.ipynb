{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VRDL_HW4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77LecHBJqaBs",
        "outputId": "bb1108b9-a360-4f44-9ffb-3c18fbe9e5c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive._mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/DL_visualization/VRDL_HW4/datasets/') "
      ],
      "metadata": {
        "id": "pANbJ5fkqab4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/HarukiYqM/pytorch-ZSSR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2uPYbMP4niH",
        "outputId": "d5263742-f88b-4062-e7f8-ae5195912e0a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'pytorch-ZSSR' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_wC-dGT5v_m",
        "outputId": "fa9a349c-de70-41e2-e177-bc2ea1f52ad1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pytorch-ZSSR  testing_lr_images  training_hr_images  train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd pytorch-ZSSR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cinQHoIP5yPO",
        "outputId": "33db38a6-afbc-4b2c-cecf-fb609b8b12bb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/DL_visualization/VRDL_HW4/datasets/pytorch-ZSSR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install GPUtil"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MudeAKK75uRa",
        "outputId": "097fa9b5-1ead-4307-a72c-8ace8868a858"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting GPUtil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "Building wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=8e09164e432d532afb3f3f29155b6635a14f5a144371d7af781ee51079f37e59\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: GPUtil\n",
            "Successfully installed GPUtil-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_ZSSR.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_7MccOn4-lC",
        "outputId": "4cdbe02a-494b-4a64-fc1c-968afe822553"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "None\n",
            "no kernel loaded\n",
            "['/content/drive/My Drive/DL_visualization/VRDL_HW4/datasets/pytorch-ZSSR/test_data/00_0.mat;']\n",
            "***** 0\n",
            "False\n",
            "** Start training for sf= [3.0, 3.0]  **\n",
            "input shape (192, 240, 3)\n",
            "sf: [3. 3.] , iteration:  0 , loss:  tensor(0.5768, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  0 reconstruct mse: 0.26855218 , true mse: None\n",
            "sf: [3. 3.] , iteration:  20 , loss:  tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  40 , loss:  tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  50 reconstruct mse: 0.003064789 , true mse: None\n",
            "sf: [3. 3.] , iteration:  60 , loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  80 , loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  100 , loss:  tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  100 reconstruct mse: 0.002871717 , true mse: None\n",
            "sf: [3. 3.] , iteration:  120 , loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  140 , loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  150 reconstruct mse: 0.002714877 , true mse: None\n",
            "sf: [3. 3.] , iteration:  160 , loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  180 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  200 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  200 reconstruct mse: 0.0026449433 , true mse: None\n",
            "sf: [3. 3.] , iteration:  220 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  240 , loss:  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  250 reconstruct mse: 0.0025504488 , true mse: None\n",
            "sf: [3. 3.] , iteration:  260 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  280 , loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -2.5109089910984054e-06 STD:  2.945907112890331e-07\n",
            "sf: [3. 3.] , iteration:  300 , loss:  tensor(0.0036, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  300 reconstruct mse: 0.0025330158 , true mse: None\n",
            "sf: [3. 3.] , iteration:  320 , loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  340 , loss:  tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  350 reconstruct mse: 0.0024890164 , true mse: None\n",
            "slope:  -1.1272975243628061e-06 STD:  1.5447045752359145e-07\n",
            "sf: [3. 3.] , iteration:  360 , loss:  tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  380 , loss:  tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  400 , loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  400 reconstruct mse: 0.0024267847 , true mse: None\n",
            "slope:  -9.954990819096604e-07 STD:  1.2596788395493386e-07\n",
            "sf: [3. 3.] , iteration:  420 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  440 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  450 reconstruct mse: 0.0023966753 , true mse: None\n",
            "sf: [3. 3.] , iteration:  460 , loss:  tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -8.275560103356906e-07 STD:  8.208542844385236e-08\n",
            "sf: [3. 3.] , iteration:  480 , loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  500 , loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  500 reconstruct mse: 0.0023726202 , true mse: None\n",
            "sf: [3. 3.] , iteration:  520 , loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -8.262647315859743e-07 STD:  8.268935034483726e-08\n",
            "sf: [3. 3.] , iteration:  540 , loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  550 reconstruct mse: 0.0023622534 , true mse: None\n",
            "sf: [3. 3.] , iteration:  560 , loss:  tensor(0.0034, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  580 , loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -6.153811700642131e-07 STD:  1.1021813733483197e-07\n",
            "sf: [3. 3.] , iteration:  600 , loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  600 reconstruct mse: 0.0023428735 , true mse: None\n",
            "sf: [3. 3.] , iteration:  620 , loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  640 , loss:  tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  650 reconstruct mse: 0.0023064534 , true mse: None\n",
            "slope:  -4.2038084939121764e-07 STD:  4.883007687644765e-08\n",
            "sf: [3. 3.] , iteration:  660 , loss:  tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  680 , loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  700 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  700 reconstruct mse: 0.0023502356 , true mse: None\n",
            "slope:  -2.011382021009922e-07 STD:  1.4371743840889686e-07\n",
            "sf: [3. 3.] , iteration:  720 , loss:  tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  740 , loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  750 reconstruct mse: 0.0023118882 , true mse: None\n",
            "sf: [3. 3.] , iteration:  760 , loss:  tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.8673669546842777e-07 STD:  1.4207161289665362e-07\n",
            "sf: [3. 3.] , iteration:  780 , loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  800 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  800 reconstruct mse: 0.002291797 , true mse: None\n",
            "sf: [3. 3.] , iteration:  820 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.9343663007021307e-07 STD:  1.4350646926086568e-07\n",
            "sf: [3. 3.] , iteration:  840 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  850 reconstruct mse: 0.0023030925 , true mse: None\n",
            "sf: [3. 3.] , iteration:  860 , loss:  tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  880 , loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.3032089918852311e-07 STD:  1.4390977402090448e-07\n",
            "sf: [3. 3.] , iteration:  900 , loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  900 reconstruct mse: 0.0022491482 , true mse: None\n",
            "sf: [3. 3.] , iteration:  920 , loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  940 , loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  950 reconstruct mse: 0.0022594465 , true mse: None\n",
            "slope:  -2.950639463961095e-07 STD:  1.0581328419962043e-07\n",
            "sf: [3. 3.] , iteration:  960 , loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  980 , loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1000 , loss:  tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1000 reconstruct mse: 0.0022292305 , true mse: None\n",
            "slope:  -3.3755786716937467e-07 STD:  1.0771313877522078e-07\n",
            "sf: [3. 3.] , iteration:  1020 , loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1040 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1050 reconstruct mse: 0.0022694117 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1060 , loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.7455872148275387e-07 STD:  1.723278744398284e-07\n",
            "sf: [3. 3.] , iteration:  1080 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1100 , loss:  tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1100 reconstruct mse: 0.0022439258 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1120 , loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -9.592622518523872e-10 STD:  1.1163940823892787e-07\n",
            "learning rate updated:  0.0001\n",
            "sf: [3. 3.] , iteration:  1140 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1150 reconstruct mse: 0.0021874183 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1160 , loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1180 , loss:  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1200 , loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1200 reconstruct mse: 0.0022097593 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1220 , loss:  tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1240 , loss:  tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1250 reconstruct mse: 0.0021433078 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1260 , loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1280 , loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1300 , loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1300 reconstruct mse: 0.0022475324 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1320 , loss:  tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1340 , loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1350 reconstruct mse: 0.0021751337 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1360 , loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1380 , loss:  tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1400 , loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1400 reconstruct mse: 0.0021647648 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1420 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.163263805210609e-07 STD:  2.917083661739091e-07\n",
            "learning rate updated:  1e-05\n",
            "sf: [3. 3.] , iteration:  1440 , loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1450 reconstruct mse: 0.0021362717 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1460 , loss:  tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1480 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1500 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1500 reconstruct mse: 0.0021749458 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1520 , loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1540 , loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1550 reconstruct mse: 0.0021872763 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1560 , loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1580 , loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1600 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1600 reconstruct mse: 0.002122351 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1620 , loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1640 , loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1650 reconstruct mse: 0.0020975037 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1660 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1680 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1700 , loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1700 reconstruct mse: 0.0020845565 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1720 , loss:  tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -5.411021411418972e-07 STD:  1.2139179064119892e-07\n",
            "sf: [3. 3.] , iteration:  1740 , loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1750 reconstruct mse: 0.0020876694 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1760 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1780 , loss:  tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -4.740161821246175e-07 STD:  1.477249180526122e-07\n",
            "sf: [3. 3.] , iteration:  1800 , loss:  tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1800 reconstruct mse: 0.0020769644 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1820 , loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1840 , loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1850 reconstruct mse: 0.0021446464 , true mse: None\n",
            "slope:  1.7338618636131437e-07 STD:  1.6947555210667625e-07\n",
            "learning rate updated:  1.0000000000000002e-06\n",
            "** Done training for sf= [3.0, 3.0]  **\n",
            "no kernel loaded\n",
            "['/content/drive/My Drive/DL_visualization/VRDL_HW4/datasets/pytorch-ZSSR/test_data/06_0.mat;']\n",
            "***** 0\n",
            "False\n",
            "** Start training for sf= [3.0, 3.0]  **\n",
            "input shape (160, 166, 3)\n",
            "sf: [3. 3.] , iteration:  0 , loss:  tensor(0.1492, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  0 reconstruct mse: 0.14300354 , true mse: None\n",
            "sf: [3. 3.] , iteration:  20 , loss:  tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  40 , loss:  tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  50 reconstruct mse: 0.003887889 , true mse: None\n",
            "sf: [3. 3.] , iteration:  60 , loss:  tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  80 , loss:  tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  100 , loss:  tensor(0.0039, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  100 reconstruct mse: 0.0037397074 , true mse: None\n",
            "sf: [3. 3.] , iteration:  120 , loss:  tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  140 , loss:  tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  150 reconstruct mse: 0.003557492 , true mse: None\n",
            "sf: [3. 3.] , iteration:  160 , loss:  tensor(0.0039, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  180 , loss:  tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  200 , loss:  tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  200 reconstruct mse: 0.0035056155 , true mse: None\n",
            "sf: [3. 3.] , iteration:  220 , loss:  tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  240 , loss:  tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  250 reconstruct mse: 0.0034092448 , true mse: None\n",
            "sf: [3. 3.] , iteration:  260 , loss:  tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  280 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -2.38276040181518e-06 STD:  2.723842265784543e-07\n",
            "sf: [3. 3.] , iteration:  300 , loss:  tensor(0.0036, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  300 reconstruct mse: 0.0033907809 , true mse: None\n",
            "sf: [3. 3.] , iteration:  320 , loss:  tensor(0.0034, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  340 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  350 reconstruct mse: 0.0033449526 , true mse: None\n",
            "slope:  -1.0798270814120782e-06 STD:  1.3408703460057862e-07\n",
            "sf: [3. 3.] , iteration:  360 , loss:  tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  380 , loss:  tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  400 , loss:  tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  400 reconstruct mse: 0.003406875 , true mse: None\n",
            "slope:  -5.235462449491127e-07 STD:  3.0308477371715467e-07\n",
            "sf: [3. 3.] , iteration:  420 , loss:  tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  440 , loss:  tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  450 reconstruct mse: 0.0033306107 , true mse: None\n",
            "sf: [3. 3.] , iteration:  460 , loss:  tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -2.823481336236058e-07 STD:  2.0997990072229566e-07\n",
            "sf: [3. 3.] , iteration:  480 , loss:  tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  500 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  500 reconstruct mse: 0.0033159133 , true mse: None\n",
            "sf: [3. 3.] , iteration:  520 , loss:  tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -3.281543031334814e-07 STD:  2.1487297663354617e-07\n",
            "sf: [3. 3.] , iteration:  540 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  550 reconstruct mse: 0.0032933194 , true mse: None\n",
            "sf: [3. 3.] , iteration:  560 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  580 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -3.8845650851726906e-07 STD:  2.178035262026059e-07\n",
            "sf: [3. 3.] , iteration:  600 , loss:  tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  600 reconstruct mse: 0.0032932465 , true mse: None\n",
            "sf: [3. 3.] , iteration:  620 , loss:  tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  640 , loss:  tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  650 reconstruct mse: 0.003238356 , true mse: None\n",
            "slope:  -4.143523983657335e-07 STD:  9.130217615354043e-08\n",
            "sf: [3. 3.] , iteration:  660 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  680 , loss:  tensor(0.0034, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  700 , loss:  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  700 reconstruct mse: 0.0032303059 , true mse: None\n",
            "slope:  -4.523564130067812e-07 STD:  8.672896496485056e-08\n",
            "sf: [3. 3.] , iteration:  720 , loss:  tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  740 , loss:  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  750 reconstruct mse: 0.0032329708 , true mse: None\n",
            "sf: [3. 3.] , iteration:  760 , loss:  tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -3.6727543920278796e-07 STD:  1.0931032030707889e-07\n",
            "sf: [3. 3.] , iteration:  780 , loss:  tensor(0.0034, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  800 , loss:  tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  800 reconstruct mse: 0.003224981 , true mse: None\n",
            "sf: [3. 3.] , iteration:  820 , loss:  tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -2.8383219614625283e-07 STD:  1.218712152034214e-07\n",
            "sf: [3. 3.] , iteration:  840 , loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  850 reconstruct mse: 0.0032317266 , true mse: None\n",
            "sf: [3. 3.] , iteration:  860 , loss:  tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  880 , loss:  tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -3.716722130775964e-08 STD:  2.7920343763982622e-08\n",
            "sf: [3. 3.] , iteration:  900 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  900 reconstruct mse: 0.0031938257 , true mse: None\n",
            "sf: [3. 3.] , iteration:  920 , loss:  tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  940 , loss:  tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  950 reconstruct mse: 0.0031636895 , true mse: None\n",
            "slope:  -3.394358791410922e-07 STD:  9.989395548252959e-08\n",
            "sf: [3. 3.] , iteration:  960 , loss:  tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  980 , loss:  tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1000 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1000 reconstruct mse: 0.0031713042 , true mse: None\n",
            "slope:  -3.507812507450525e-07 STD:  9.60948845341775e-08\n",
            "sf: [3. 3.] , iteration:  1020 , loss:  tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1040 , loss:  tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1050 reconstruct mse: 0.0031767723 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1060 , loss:  tensor(0.0034, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -2.648602239787556e-07 STD:  1.257803197076713e-07\n",
            "sf: [3. 3.] , iteration:  1080 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1100 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1100 reconstruct mse: 0.003148058 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1120 , loss:  tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.5690550208091635e-07 STD:  8.313499988271631e-08\n",
            "sf: [3. 3.] , iteration:  1140 , loss:  tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1150 reconstruct mse: 0.0031421634 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1160 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1180 , loss:  tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.3259705156088008e-07 STD:  7.686567153582791e-08\n",
            "sf: [3. 3.] , iteration:  1200 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1200 reconstruct mse: 0.003153325 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1220 , loss:  tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1240 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1250 reconstruct mse: 0.0030949966 , true mse: None\n",
            "slope:  -3.165686503052705e-07 STD:  1.1957556196501228e-07\n",
            "sf: [3. 3.] , iteration:  1260 , loss:  tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1280 , loss:  tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1300 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1300 reconstruct mse: 0.0030923581 , true mse: None\n",
            "slope:  -3.17133031785489e-07 STD:  1.196082909801117e-07\n",
            "sf: [3. 3.] , iteration:  1320 , loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1340 , loss:  tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1350 reconstruct mse: 0.0030939463 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1360 , loss:  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -3.148023970425153e-07 STD:  1.2025296051275655e-07\n",
            "sf: [3. 3.] , iteration:  1380 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1400 , loss:  tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1400 reconstruct mse: 0.0030709857 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1420 , loss:  tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -3.314581699669387e-07 STD:  1.1846590852460507e-07\n",
            "sf: [3. 3.] , iteration:  1440 , loss:  tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1450 reconstruct mse: 0.0030556472 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1460 , loss:  tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1480 , loss:  tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -2.0014215260744233e-07 STD:  5.5668254157538434e-08\n",
            "sf: [3. 3.] , iteration:  1500 , loss:  tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1500 reconstruct mse: 0.0030579525 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1520 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1540 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1550 reconstruct mse: 0.003084557 , true mse: None\n",
            "slope:  -6.362376734614194e-08 STD:  1.1558431415604131e-07\n",
            "learning rate updated:  0.0001\n",
            "sf: [3. 3.] , iteration:  1560 , loss:  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1580 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1600 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1600 reconstruct mse: 0.003077926 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1620 , loss:  tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1640 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1650 reconstruct mse: 0.0030541522 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1660 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1680 , loss:  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1700 , loss:  tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1700 reconstruct mse: 0.0030429456 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1720 , loss:  tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1740 , loss:  tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1750 reconstruct mse: 0.003058092 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1760 , loss:  tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1780 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1800 , loss:  tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1800 reconstruct mse: 0.003045046 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1820 , loss:  tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1840 , loss:  tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1850 reconstruct mse: 0.0030304992 , true mse: None\n",
            "slope:  -9.041139855980338e-08 STD:  5.873385440175825e-08\n",
            "sf: [3. 3.] , iteration:  1860 , loss:  tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1880 , loss:  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1900 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1900 reconstruct mse: 0.0029933953 , true mse: None\n",
            "slope:  -2.5338679552077967e-07 STD:  1.057251464550319e-07\n",
            "sf: [3. 3.] , iteration:  1920 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1940 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1950 reconstruct mse: 0.0030201133 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1960 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -2.5521591305733177e-07 STD:  1.0478108829060282e-07\n",
            "sf: [3. 3.] , iteration:  1980 , loss:  tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  2000 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  2000 reconstruct mse: 0.002947096 , true mse: None\n",
            "sf: [3. 3.] , iteration:  2020 , loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -4.125717096030745e-07 STD:  1.5009311816928798e-07\n",
            "sf: [3. 3.] , iteration:  2040 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  2050 reconstruct mse: 0.0029956922 , true mse: None\n",
            "sf: [3. 3.] , iteration:  2060 , loss:  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  2080 , loss:  tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -2.3182667791843533e-07 STD:  1.938143369984152e-07\n",
            "sf: [3. 3.] , iteration:  2100 , loss:  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  2100 reconstruct mse: 0.0029682363 , true mse: None\n",
            "sf: [3. 3.] , iteration:  2120 , loss:  tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  2140 , loss:  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  2150 reconstruct mse: 0.003002167 , true mse: None\n",
            "slope:  -2.9504764825104686e-08 STD:  2.105278926073213e-07\n",
            "learning rate updated:  1e-05\n",
            "sf: [3. 3.] , iteration:  2160 , loss:  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  2180 , loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  2200 , loss:  tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  2200 reconstruct mse: 0.0029555403 , true mse: None\n",
            "sf: [3. 3.] , iteration:  2220 , loss:  tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  2240 , loss:  tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  2250 reconstruct mse: 0.002992389 , true mse: None\n",
            "sf: [3. 3.] , iteration:  2260 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  2280 , loss:  tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  2300 , loss:  tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  2300 reconstruct mse: 0.0029382699 , true mse: None\n",
            "sf: [3. 3.] , iteration:  2320 , loss:  tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  2340 , loss:  tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  2350 reconstruct mse: 0.0029230914 , true mse: None\n",
            "sf: [3. 3.] , iteration:  2360 , loss:  tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  2380 , loss:  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  2400 , loss:  tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  2400 reconstruct mse: 0.002897551 , true mse: None\n",
            "sf: [3. 3.] , iteration:  2420 , loss:  tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  2440 , loss:  tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  2450 reconstruct mse: 0.0029373127 , true mse: None\n",
            "slope:  -3.0174292623996536e-07 STD:  1.8404676585285966e-07\n",
            "sf: [3. 3.] , iteration:  2460 , loss:  tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  2480 , loss:  tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  2500 , loss:  tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  2500 reconstruct mse: 0.0028916113 , true mse: None\n",
            "slope:  -1.5819165855645665e-07 STD:  1.3154172490393454e-07\n",
            "sf: [3. 3.] , iteration:  2520 , loss:  tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  2540 , loss:  tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  2550 reconstruct mse: 0.002875786 , true mse: None\n",
            "sf: [3. 3.] , iteration:  2560 , loss:  tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -2.011009491980078e-07 STD:  1.3897455319317918e-07\n",
            "sf: [3. 3.] , iteration:  2580 , loss:  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  2600 , loss:  tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  2600 reconstruct mse: 0.0029097404 , true mse: None\n",
            "sf: [3. 3.] , iteration:  2620 , loss:  tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -7.429579272866022e-08 STD:  1.6260353286518324e-07\n",
            "learning rate updated:  1.0000000000000002e-06\n",
            "** Done training for sf= [3.0, 3.0]  **\n",
            "no kernel loaded\n",
            "['/content/drive/My Drive/DL_visualization/VRDL_HW4/datasets/pytorch-ZSSR/test_data/03_0.mat;']\n",
            "***** 0\n",
            "False\n",
            "** Start training for sf= [3.0, 3.0]  **\n",
            "input shape (92, 92, 3)\n",
            "sf: [3. 3.] , iteration:  0 , loss:  tensor(0.1284, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  0 reconstruct mse: 0.15454352 , true mse: None\n",
            "sf: [3. 3.] , iteration:  20 , loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  40 , loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  50 reconstruct mse: 0.0014119103 , true mse: None\n",
            "sf: [3. 3.] , iteration:  60 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  80 , loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  100 , loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  100 reconstruct mse: 0.0015250877 , true mse: None\n",
            "sf: [3. 3.] , iteration:  120 , loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  140 , loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  150 reconstruct mse: 0.0015065359 , true mse: None\n",
            "sf: [3. 3.] , iteration:  160 , loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  180 , loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  200 , loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  200 reconstruct mse: 0.0015151459 , true mse: None\n",
            "sf: [3. 3.] , iteration:  220 , loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  240 , loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  250 reconstruct mse: 0.001349048 , true mse: None\n",
            "sf: [3. 3.] , iteration:  260 , loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  280 , loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -2.713329158723365e-07 STD:  5.44224966424764e-07\n",
            "learning rate updated:  0.0001\n",
            "sf: [3. 3.] , iteration:  300 , loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  300 reconstruct mse: 0.0014409471 , true mse: None\n",
            "sf: [3. 3.] , iteration:  320 , loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  340 , loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  350 reconstruct mse: 0.0014210708 , true mse: None\n",
            "sf: [3. 3.] , iteration:  360 , loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  380 , loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  400 , loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  400 reconstruct mse: 0.0013327579 , true mse: None\n",
            "sf: [3. 3.] , iteration:  420 , loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  440 , loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  450 reconstruct mse: 0.0013561528 , true mse: None\n",
            "sf: [3. 3.] , iteration:  460 , loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  480 , loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  500 , loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  500 reconstruct mse: 0.0013994572 , true mse: None\n",
            "sf: [3. 3.] , iteration:  520 , loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  540 , loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  550 reconstruct mse: 0.0012580843 , true mse: None\n",
            "sf: [3. 3.] , iteration:  560 , loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  580 , loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -5.185471381992119e-07 STD:  3.558468355465669e-07\n",
            "sf: [3. 3.] , iteration:  600 , loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  600 reconstruct mse: 0.0012589883 , true mse: None\n",
            "sf: [3. 3.] , iteration:  620 , loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  640 , loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  650 reconstruct mse: 0.0012231965 , true mse: None\n",
            "slope:  -8.127631153911315e-07 STD:  2.796318124341062e-07\n",
            "sf: [3. 3.] , iteration:  660 , loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  680 , loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  700 , loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  700 reconstruct mse: 0.0011334436 , true mse: None\n",
            "slope:  -1.1338302865624432e-06 STD:  2.460566861866324e-07\n",
            "sf: [3. 3.] , iteration:  720 , loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  740 , loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  750 reconstruct mse: 0.0012017484 , true mse: None\n",
            "sf: [3. 3.] , iteration:  760 , loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -4.7643319703638556e-07 STD:  2.5847532466769934e-07\n",
            "sf: [3. 3.] , iteration:  780 , loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  800 , loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  800 reconstruct mse: 0.0012832169 , true mse: None\n",
            "sf: [3. 3.] , iteration:  820 , loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  5.401810631155977e-08 STD:  4.207738452328966e-07\n",
            "learning rate updated:  1e-05\n",
            "sf: [3. 3.] , iteration:  840 , loss:  tensor(0.0007, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  850 reconstruct mse: 0.0012301187 , true mse: None\n",
            "sf: [3. 3.] , iteration:  860 , loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  880 , loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  900 , loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  900 reconstruct mse: 0.0012779612 , true mse: None\n",
            "sf: [3. 3.] , iteration:  920 , loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  940 , loss:  tensor(0.0004, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  950 reconstruct mse: 0.0011430624 , true mse: None\n",
            "sf: [3. 3.] , iteration:  960 , loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  980 , loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1000 , loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1000 reconstruct mse: 0.0011567338 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1020 , loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1040 , loss:  tensor(0.0006, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1050 reconstruct mse: 0.0011898413 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1060 , loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1080 , loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1100 , loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1100 reconstruct mse: 0.001353575 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1120 , loss:  tensor(0.0005, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  3.9601325988769797e-07 STD:  6.112611396919985e-07\n",
            "learning rate updated:  1.0000000000000002e-06\n",
            "** Done training for sf= [3.0, 3.0]  **\n",
            "no kernel loaded\n",
            "['/content/drive/My Drive/DL_visualization/VRDL_HW4/datasets/pytorch-ZSSR/test_data/05_0.mat;']\n",
            "***** 0\n",
            "False\n",
            "** Start training for sf= [3.0, 3.0]  **\n",
            "input shape (96, 117, 3)\n",
            "sf: [3. 3.] , iteration:  0 , loss:  tensor(0.0222, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  0 reconstruct mse: 0.34084818 , true mse: None\n",
            "sf: [3. 3.] , iteration:  20 , loss:  tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  40 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  50 reconstruct mse: 0.0038963878 , true mse: None\n",
            "sf: [3. 3.] , iteration:  60 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  80 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  100 , loss:  tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  100 reconstruct mse: 0.003622478 , true mse: None\n",
            "sf: [3. 3.] , iteration:  120 , loss:  tensor(0.0025, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  140 , loss:  tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  150 reconstruct mse: 0.0030384746 , true mse: None\n",
            "sf: [3. 3.] , iteration:  160 , loss:  tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  180 , loss:  tensor(0.0039, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  200 , loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  200 reconstruct mse: 0.0029171393 , true mse: None\n",
            "sf: [3. 3.] , iteration:  220 , loss:  tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  240 , loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  250 reconstruct mse: 0.0028661583 , true mse: None\n",
            "sf: [3. 3.] , iteration:  260 , loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  280 , loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -5.5315955542028e-06 STD:  1.1124986750822044e-06\n",
            "sf: [3. 3.] , iteration:  300 , loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  300 reconstruct mse: 0.0029127111 , true mse: None\n",
            "sf: [3. 3.] , iteration:  320 , loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  340 , loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  350 reconstruct mse: 0.0026438143 , true mse: None\n",
            "slope:  -1.5874975360929928e-06 STD:  5.220588367217767e-07\n",
            "sf: [3. 3.] , iteration:  360 , loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  380 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  400 , loss:  tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  400 reconstruct mse: 0.0024868126 , true mse: None\n",
            "slope:  -2.1659946069121437e-06 STD:  6.322791097491222e-07\n",
            "sf: [3. 3.] , iteration:  420 , loss:  tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  440 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  450 reconstruct mse: 0.002340706 , true mse: None\n",
            "sf: [3. 3.] , iteration:  460 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -2.9536057263612775e-06 STD:  5.161131755035896e-07\n",
            "sf: [3. 3.] , iteration:  480 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  500 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  500 reconstruct mse: 0.002174211 , true mse: None\n",
            "sf: [3. 3.] , iteration:  520 , loss:  tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -3.5602170974016146e-06 STD:  2.618550562769784e-07\n",
            "sf: [3. 3.] , iteration:  540 , loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  550 reconstruct mse: 0.0021473905 , true mse: None\n",
            "sf: [3. 3.] , iteration:  560 , loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  580 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -2.6108985766768524e-06 STD:  2.8970925852508126e-07\n",
            "sf: [3. 3.] , iteration:  600 , loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  600 reconstruct mse: 0.0020088623 , true mse: None\n",
            "sf: [3. 3.] , iteration:  620 , loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  640 , loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  650 reconstruct mse: 0.0019936191 , true mse: None\n",
            "slope:  -1.7190449871122806e-06 STD:  2.829964841581975e-07\n",
            "sf: [3. 3.] , iteration:  660 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  680 , loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  700 , loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  700 reconstruct mse: 0.0021858674 , true mse: None\n",
            "slope:  -2.609170041978361e-07 STD:  6.636018632977784e-07\n",
            "learning rate updated:  0.0001\n",
            "sf: [3. 3.] , iteration:  720 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  740 , loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  750 reconstruct mse: 0.001976882 , true mse: None\n",
            "sf: [3. 3.] , iteration:  760 , loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  780 , loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  800 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  800 reconstruct mse: 0.0021316183 , true mse: None\n",
            "sf: [3. 3.] , iteration:  820 , loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  840 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  850 reconstruct mse: 0.0019630925 , true mse: None\n",
            "sf: [3. 3.] , iteration:  860 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  880 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  900 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  900 reconstruct mse: 0.0019336066 , true mse: None\n",
            "sf: [3. 3.] , iteration:  920 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  940 , loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  950 reconstruct mse: 0.0018450964 , true mse: None\n",
            "sf: [3. 3.] , iteration:  960 , loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  980 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1000 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1000 reconstruct mse: 0.0018919214 , true mse: None\n",
            "slope:  -1.1947799939662195e-06 STD:  4.0114435663367607e-07\n",
            "sf: [3. 3.] , iteration:  1020 , loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1040 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1050 reconstruct mse: 0.0017190553 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1060 , loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.0595188941806502e-06 STD:  3.372632769125403e-07\n",
            "sf: [3. 3.] , iteration:  1080 , loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1100 , loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1100 reconstruct mse: 0.0018235152 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1120 , loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -6.924476474523536e-07 STD:  4.375909606198332e-07\n",
            "sf: [3. 3.] , iteration:  1140 , loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1150 reconstruct mse: 0.0016811624 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1160 , loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1180 , loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -7.925482932478189e-07 STD:  4.5751761272901294e-07\n",
            "sf: [3. 3.] , iteration:  1200 , loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1200 reconstruct mse: 0.0016798758 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1220 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1240 , loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1250 reconstruct mse: 0.0016324521 , true mse: None\n",
            "slope:  -6.336916703730767e-07 STD:  3.7669532879650915e-07\n",
            "sf: [3. 3.] , iteration:  1260 , loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1280 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1300 , loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1300 reconstruct mse: 0.0015830506 , true mse: None\n",
            "slope:  -1.059278845787051e-06 STD:  2.3681682676871686e-07\n",
            "sf: [3. 3.] , iteration:  1320 , loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1340 , loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1350 reconstruct mse: 0.0015388468 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1360 , loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -7.629129104316202e-07 STD:  1.0544199344067129e-07\n",
            "sf: [3. 3.] , iteration:  1380 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1400 , loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1400 reconstruct mse: 0.001681564 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1420 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.8045771867036694e-07 STD:  4.414735280002928e-07\n",
            "learning rate updated:  1e-05\n",
            "sf: [3. 3.] , iteration:  1440 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1450 reconstruct mse: 0.0015729776 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1460 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1480 , loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1500 , loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1500 reconstruct mse: 0.0015767543 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1520 , loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1540 , loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1550 reconstruct mse: 0.0014372015 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1560 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1580 , loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1600 , loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1600 reconstruct mse: 0.0015990768 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1620 , loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1640 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1650 reconstruct mse: 0.0014671857 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1660 , loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1680 , loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1700 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1700 reconstruct mse: 0.0015242238 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1720 , loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.5015341341495673e-07 STD:  4.975857687876951e-07\n",
            "learning rate updated:  1.0000000000000002e-06\n",
            "** Done training for sf= [3.0, 3.0]  **\n",
            "no kernel loaded\n",
            "['/content/drive/My Drive/DL_visualization/VRDL_HW4/datasets/pytorch-ZSSR/test_data/11_0.mat;']\n",
            "***** 0\n",
            "False\n",
            "** Start training for sf= [3.0, 3.0]  **\n",
            "input shape (120, 83, 3)\n",
            "sf: [3. 3.] , iteration:  0 , loss:  tensor(0.8876, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  0 reconstruct mse: 0.22585168 , true mse: None\n",
            "sf: [3. 3.] , iteration:  20 , loss:  tensor(0.0073, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  40 , loss:  tensor(0.0053, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  50 reconstruct mse: 0.009894618 , true mse: None\n",
            "sf: [3. 3.] , iteration:  60 , loss:  tensor(0.0055, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  80 , loss:  tensor(0.0036, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  100 , loss:  tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  100 reconstruct mse: 0.010056352 , true mse: None\n",
            "sf: [3. 3.] , iteration:  120 , loss:  tensor(0.0054, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  140 , loss:  tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  150 reconstruct mse: 0.009601015 , true mse: None\n",
            "sf: [3. 3.] , iteration:  160 , loss:  tensor(0.0057, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  180 , loss:  tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  200 , loss:  tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  200 reconstruct mse: 0.00968891 , true mse: None\n",
            "sf: [3. 3.] , iteration:  220 , loss:  tensor(0.0061, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  240 , loss:  tensor(0.0057, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  250 reconstruct mse: 0.009248081 , true mse: None\n",
            "sf: [3. 3.] , iteration:  260 , loss:  tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  280 , loss:  tensor(0.0054, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -3.3210329711437376e-06 STD:  1.1733677072273967e-06\n",
            "sf: [3. 3.] , iteration:  300 , loss:  tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  300 reconstruct mse: 0.009243711 , true mse: None\n",
            "sf: [3. 3.] , iteration:  320 , loss:  tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  340 , loss:  tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  350 reconstruct mse: 0.009016275 , true mse: None\n",
            "slope:  -3.22935543954372e-06 STD:  8.144232353179915e-07\n",
            "sf: [3. 3.] , iteration:  360 , loss:  tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  380 , loss:  tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  400 , loss:  tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  400 reconstruct mse: 0.008925574 , true mse: None\n",
            "slope:  -3.516955301165598e-06 STD:  7.311340391665697e-07\n",
            "sf: [3. 3.] , iteration:  420 , loss:  tensor(0.0047, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  440 , loss:  tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  450 reconstruct mse: 0.008813942 , true mse: None\n",
            "sf: [3. 3.] , iteration:  460 , loss:  tensor(0.0052, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -2.3728292435407783e-06 STD:  3.335341890337778e-07\n",
            "sf: [3. 3.] , iteration:  480 , loss:  tensor(0.0053, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  500 , loss:  tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  500 reconstruct mse: 0.008872716 , true mse: None\n",
            "sf: [3. 3.] , iteration:  520 , loss:  tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.8886476755142007e-06 STD:  5.606857670687229e-07\n",
            "sf: [3. 3.] , iteration:  540 , loss:  tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  550 reconstruct mse: 0.008813683 , true mse: None\n",
            "sf: [3. 3.] , iteration:  560 , loss:  tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  580 , loss:  tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -9.160861372947676e-07 STD:  3.291669434211449e-07\n",
            "sf: [3. 3.] , iteration:  600 , loss:  tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  600 reconstruct mse: 0.0090105785 , true mse: None\n",
            "sf: [3. 3.] , iteration:  620 , loss:  tensor(0.0051, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  640 , loss:  tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  650 reconstruct mse: 0.008704513 , true mse: None\n",
            "slope:  -1.6198866069314934e-07 STD:  8.098721292358198e-07\n",
            "learning rate updated:  0.0001\n",
            "sf: [3. 3.] , iteration:  660 , loss:  tensor(0.0051, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  680 , loss:  tensor(0.0050, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  700 , loss:  tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  700 reconstruct mse: 0.008540325 , true mse: None\n",
            "sf: [3. 3.] , iteration:  720 , loss:  tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  740 , loss:  tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  750 reconstruct mse: 0.008888203 , true mse: None\n",
            "sf: [3. 3.] , iteration:  760 , loss:  tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  780 , loss:  tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  800 , loss:  tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  800 reconstruct mse: 0.008943475 , true mse: None\n",
            "sf: [3. 3.] , iteration:  820 , loss:  tensor(0.0039, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  840 , loss:  tensor(0.0036, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  850 reconstruct mse: 0.008378874 , true mse: None\n",
            "sf: [3. 3.] , iteration:  860 , loss:  tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  880 , loss:  tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  900 , loss:  tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  900 reconstruct mse: 0.00838569 , true mse: None\n",
            "sf: [3. 3.] , iteration:  920 , loss:  tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  940 , loss:  tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  950 reconstruct mse: 0.0084059285 , true mse: None\n",
            "slope:  -3.044666722416881e-06 STD:  1.1649000014055219e-06\n",
            "sf: [3. 3.] , iteration:  960 , loss:  tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  980 , loss:  tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1000 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1000 reconstruct mse: 0.008660792 , true mse: None\n",
            "slope:  -1.0766200721263711e-06 STD:  1.6932638452579177e-06\n",
            "learning rate updated:  1e-05\n",
            "sf: [3. 3.] , iteration:  1020 , loss:  tensor(0.0050, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1040 , loss:  tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1050 reconstruct mse: 0.008281027 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1060 , loss:  tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1080 , loss:  tensor(0.0034, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1100 , loss:  tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1100 reconstruct mse: 0.008232566 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1120 , loss:  tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1140 , loss:  tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1150 reconstruct mse: 0.008281908 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1160 , loss:  tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1180 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1200 , loss:  tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1200 reconstruct mse: 0.00822904 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1220 , loss:  tensor(0.0034, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1240 , loss:  tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1250 reconstruct mse: 0.0080567915 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1260 , loss:  tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1280 , loss:  tensor(0.0047, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1300 , loss:  tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1300 reconstruct mse: 0.008213608 , true mse: None\n",
            "slope:  -5.260650068521581e-07 STD:  5.45884704099299e-07\n",
            "sf: [3. 3.] , iteration:  1320 , loss:  tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1340 , loss:  tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1350 reconstruct mse: 0.008456677 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1360 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  6.682127714157054e-07 STD:  9.773123793099373e-07\n",
            "learning rate updated:  1.0000000000000002e-06\n",
            "** Done training for sf= [3.0, 3.0]  **\n",
            "no kernel loaded\n",
            "['/content/drive/My Drive/DL_visualization/VRDL_HW4/datasets/pytorch-ZSSR/test_data/02_0.mat;']\n",
            "***** 0\n",
            "False\n",
            "** Start training for sf= [3.0, 3.0]  **\n",
            "input shape (170, 170, 3)\n",
            "sf: [3. 3.] , iteration:  0 , loss:  tensor(0.4733, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  0 reconstruct mse: 0.19977143 , true mse: None\n",
            "sf: [3. 3.] , iteration:  20 , loss:  tensor(0.0036, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  40 , loss:  tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  50 reconstruct mse: 0.0025713 , true mse: None\n",
            "sf: [3. 3.] , iteration:  60 , loss:  tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  80 , loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  100 , loss:  tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  100 reconstruct mse: 0.0022192558 , true mse: None\n",
            "sf: [3. 3.] , iteration:  120 , loss:  tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  140 , loss:  tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  150 reconstruct mse: 0.0020068898 , true mse: None\n",
            "sf: [3. 3.] , iteration:  160 , loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  180 , loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  200 , loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  200 reconstruct mse: 0.0018987486 , true mse: None\n",
            "sf: [3. 3.] , iteration:  220 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  240 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  250 reconstruct mse: 0.001803355 , true mse: None\n",
            "sf: [3. 3.] , iteration:  260 , loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  280 , loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -3.71279427781701e-06 STD:  6.206921785663292e-07\n",
            "sf: [3. 3.] , iteration:  300 , loss:  tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  300 reconstruct mse: 0.0017827587 , true mse: None\n",
            "sf: [3. 3.] , iteration:  320 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  340 , loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  350 reconstruct mse: 0.0016916043 , true mse: None\n",
            "slope:  -1.4931217301636931e-06 STD:  1.6945385113755595e-07\n",
            "sf: [3. 3.] , iteration:  360 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  380 , loss:  tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  400 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  400 reconstruct mse: 0.0015933953 , true mse: None\n",
            "slope:  -1.4449146110564517e-06 STD:  1.508984745749054e-07\n",
            "sf: [3. 3.] , iteration:  420 , loss:  tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  440 , loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  450 reconstruct mse: 0.0015499508 , true mse: None\n",
            "sf: [3. 3.] , iteration:  460 , loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.3923435471951986e-06 STD:  1.5359619294348605e-07\n",
            "sf: [3. 3.] , iteration:  480 , loss:  tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  500 , loss:  tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  500 reconstruct mse: 0.0015346669 , true mse: None\n",
            "sf: [3. 3.] , iteration:  520 , loss:  tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.2756744399666758e-06 STD:  2.091808343109062e-07\n",
            "sf: [3. 3.] , iteration:  540 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  550 reconstruct mse: 0.0014915693 , true mse: None\n",
            "sf: [3. 3.] , iteration:  560 , loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  580 , loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -9.175965096801524e-07 STD:  1.6581492872249108e-07\n",
            "sf: [3. 3.] , iteration:  600 , loss:  tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  600 reconstruct mse: 0.0015425369 , true mse: None\n",
            "sf: [3. 3.] , iteration:  620 , loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  640 , loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  650 reconstruct mse: 0.0014697403 , true mse: None\n",
            "slope:  -3.051019739359586e-07 STD:  1.8621222206317525e-07\n",
            "sf: [3. 3.] , iteration:  660 , loss:  tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  680 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  700 , loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  700 reconstruct mse: 0.001420094 , true mse: None\n",
            "slope:  -5.01949340105056e-07 STD:  2.2334929683263605e-07\n",
            "sf: [3. 3.] , iteration:  720 , loss:  tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  740 , loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  750 reconstruct mse: 0.001402326 , true mse: None\n",
            "sf: [3. 3.] , iteration:  760 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -6.018588319420857e-07 STD:  2.199626069623823e-07\n",
            "sf: [3. 3.] , iteration:  780 , loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  800 , loss:  tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  800 reconstruct mse: 0.00141746 , true mse: None\n",
            "sf: [3. 3.] , iteration:  820 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -6.35135918855669e-07 STD:  2.0307321771523592e-07\n",
            "sf: [3. 3.] , iteration:  840 , loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  850 reconstruct mse: 0.0013783969 , true mse: None\n",
            "sf: [3. 3.] , iteration:  860 , loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  880 , loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -3.7064170464873415e-07 STD:  1.189199750226116e-07\n",
            "sf: [3. 3.] , iteration:  900 , loss:  tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  900 reconstruct mse: 0.0013677429 , true mse: None\n",
            "sf: [3. 3.] , iteration:  920 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  940 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  950 reconstruct mse: 0.0013494918 , true mse: None\n",
            "slope:  -3.1077140010893184e-07 STD:  8.35267186109783e-08\n",
            "sf: [3. 3.] , iteration:  960 , loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  980 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1000 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1000 reconstruct mse: 0.0013662934 , true mse: None\n",
            "slope:  -2.624767366796706e-07 STD:  1.0753835154302942e-07\n",
            "sf: [3. 3.] , iteration:  1020 , loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1040 , loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1050 reconstruct mse: 0.0014036451 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1060 , loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  9.809411130845508e-08 STD:  1.3430698848452844e-07\n",
            "learning rate updated:  0.0001\n",
            "sf: [3. 3.] , iteration:  1080 , loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1100 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1100 reconstruct mse: 0.0013069453 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1120 , loss:  tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1140 , loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1150 reconstruct mse: 0.0012846523 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1160 , loss:  tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1180 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1200 , loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1200 reconstruct mse: 0.0013235763 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1220 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1240 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1250 reconstruct mse: 0.0012846444 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1260 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1280 , loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1300 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1300 reconstruct mse: 0.0013035344 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1320 , loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1340 , loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1350 reconstruct mse: 0.0012828577 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1360 , loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -4.7262059524654906e-08 STD:  1.2605344232799732e-07\n",
            "learning rate updated:  1e-05\n",
            "sf: [3. 3.] , iteration:  1380 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1400 , loss:  tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1400 reconstruct mse: 0.0012616247 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1420 , loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1440 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1450 reconstruct mse: 0.0012837972 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1460 , loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1480 , loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1500 , loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1500 reconstruct mse: 0.0012860602 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1520 , loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1540 , loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1550 reconstruct mse: 0.0013058698 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1560 , loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1580 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1600 , loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1600 reconstruct mse: 0.0012423788 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1620 , loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1640 , loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1650 reconstruct mse: 0.0012426163 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1660 , loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -2.520862035453316e-07 STD:  1.476955211795806e-07\n",
            "sf: [3. 3.] , iteration:  1680 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1700 , loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1700 reconstruct mse: 0.0012993527 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1720 , loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -7.333676330745674e-08 STD:  2.2049596730427367e-07\n",
            "learning rate updated:  1.0000000000000002e-06\n",
            "** Done training for sf= [3.0, 3.0]  **\n",
            "no kernel loaded\n",
            "['/content/drive/My Drive/DL_visualization/VRDL_HW4/datasets/pytorch-ZSSR/test_data/09_0.mat;']\n",
            "***** 0\n",
            "False\n",
            "** Start training for sf= [3.0, 3.0]  **\n",
            "input shape (218, 176, 3)\n",
            "sf: [3. 3.] , iteration:  0 , loss:  tensor(0.1625, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  0 reconstruct mse: 0.15024398 , true mse: None\n",
            "sf: [3. 3.] , iteration:  20 , loss:  tensor(0.0166, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  40 , loss:  tensor(0.0164, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  50 reconstruct mse: 0.011532895 , true mse: None\n",
            "sf: [3. 3.] , iteration:  60 , loss:  tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  80 , loss:  tensor(0.0150, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  100 , loss:  tensor(0.0073, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  100 reconstruct mse: 0.010741845 , true mse: None\n",
            "sf: [3. 3.] , iteration:  120 , loss:  tensor(0.0143, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  140 , loss:  tensor(0.0096, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  150 reconstruct mse: 0.010119973 , true mse: None\n",
            "sf: [3. 3.] , iteration:  160 , loss:  tensor(0.0090, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  180 , loss:  tensor(0.0102, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  200 , loss:  tensor(0.0073, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  200 reconstruct mse: 0.009674984 , true mse: None\n",
            "sf: [3. 3.] , iteration:  220 , loss:  tensor(0.0069, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  240 , loss:  tensor(0.0076, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  250 reconstruct mse: 0.009439434 , true mse: None\n",
            "sf: [3. 3.] , iteration:  260 , loss:  tensor(0.0063, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  280 , loss:  tensor(0.0069, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.0507566854357725e-05 STD:  1.2577523947538262e-06\n",
            "sf: [3. 3.] , iteration:  300 , loss:  tensor(0.0132, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  300 reconstruct mse: 0.009228619 , true mse: None\n",
            "sf: [3. 3.] , iteration:  320 , loss:  tensor(0.0066, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  340 , loss:  tensor(0.0102, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  350 reconstruct mse: 0.008930138 , true mse: None\n",
            "slope:  -5.652068182826043e-06 STD:  4.6351722752114375e-07\n",
            "sf: [3. 3.] , iteration:  360 , loss:  tensor(0.0078, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  380 , loss:  tensor(0.0068, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  400 , loss:  tensor(0.0153, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  400 reconstruct mse: 0.008873831 , true mse: None\n",
            "slope:  -4.22320514917377e-06 STD:  4.1248251075387277e-07\n",
            "sf: [3. 3.] , iteration:  420 , loss:  tensor(0.0107, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  440 , loss:  tensor(0.0135, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  450 reconstruct mse: 0.008819642 , true mse: None\n",
            "sf: [3. 3.] , iteration:  460 , loss:  tensor(0.0063, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -3.1887460500002084e-06 STD:  6.05323961037278e-07\n",
            "sf: [3. 3.] , iteration:  480 , loss:  tensor(0.0100, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  500 , loss:  tensor(0.0106, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  500 reconstruct mse: 0.008683013 , true mse: None\n",
            "sf: [3. 3.] , iteration:  520 , loss:  tensor(0.0100, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -2.4034176021814157e-06 STD:  4.961935984508698e-07\n",
            "sf: [3. 3.] , iteration:  540 , loss:  tensor(0.0061, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  550 reconstruct mse: 0.008532013 , true mse: None\n",
            "sf: [3. 3.] , iteration:  560 , loss:  tensor(0.0064, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  580 , loss:  tensor(0.0140, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.9741374999284697e-06 STD:  2.7417074641243324e-07\n",
            "sf: [3. 3.] , iteration:  600 , loss:  tensor(0.0060, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  600 reconstruct mse: 0.008451875 , true mse: None\n",
            "sf: [3. 3.] , iteration:  620 , loss:  tensor(0.0092, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  640 , loss:  tensor(0.0058, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  650 reconstruct mse: 0.008409799 , true mse: None\n",
            "slope:  -2.1016448736190726e-06 STD:  2.6586498050572175e-07\n",
            "sf: [3. 3.] , iteration:  660 , loss:  tensor(0.0076, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  680 , loss:  tensor(0.0093, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  700 , loss:  tensor(0.0057, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  700 reconstruct mse: 0.008434551 , true mse: None\n",
            "slope:  -1.2382753193378503e-06 STD:  3.811531728214312e-07\n",
            "sf: [3. 3.] , iteration:  720 , loss:  tensor(0.0053, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  740 , loss:  tensor(0.0058, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  750 reconstruct mse: 0.008095018 , true mse: None\n",
            "sf: [3. 3.] , iteration:  760 , loss:  tensor(0.0090, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.7826296389103108e-06 STD:  6.713201472034638e-07\n",
            "sf: [3. 3.] , iteration:  780 , loss:  tensor(0.0068, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  800 , loss:  tensor(0.0058, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  800 reconstruct mse: 0.008135221 , true mse: None\n",
            "sf: [3. 3.] , iteration:  820 , loss:  tensor(0.0061, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.8961802124977036e-06 STD:  6.569446411590222e-07\n",
            "sf: [3. 3.] , iteration:  840 , loss:  tensor(0.0057, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  850 reconstruct mse: 0.007853072 , true mse: None\n",
            "sf: [3. 3.] , iteration:  860 , loss:  tensor(0.0062, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  880 , loss:  tensor(0.0097, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -2.825567498803141e-06 STD:  6.72943004765816e-07\n",
            "sf: [3. 3.] , iteration:  900 , loss:  tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  900 reconstruct mse: 0.00811207 , true mse: None\n",
            "sf: [3. 3.] , iteration:  920 , loss:  tensor(0.0057, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  940 , loss:  tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  950 reconstruct mse: 0.007826362 , true mse: None\n",
            "slope:  -1.120924949645998e-06 STD:  8.952052404705954e-07\n",
            "sf: [3. 3.] , iteration:  960 , loss:  tensor(0.0057, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  980 , loss:  tensor(0.0096, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1000 , loss:  tensor(0.0104, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1000 reconstruct mse: 0.0077333236 , true mse: None\n",
            "slope:  -1.6610100865363927e-06 STD:  9.063590220056625e-07\n",
            "sf: [3. 3.] , iteration:  1020 , loss:  tensor(0.0051, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1040 , loss:  tensor(0.0111, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1050 reconstruct mse: 0.0076699406 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1060 , loss:  tensor(0.0117, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.4900192618369935e-06 STD:  8.882168907538838e-07\n",
            "sf: [3. 3.] , iteration:  1080 , loss:  tensor(0.0059, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1100 , loss:  tensor(0.0096, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1100 reconstruct mse: 0.0076119504 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1120 , loss:  tensor(0.0064, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -2.3133214563131276e-06 STD:  5.239648384586648e-07\n",
            "sf: [3. 3.] , iteration:  1140 , loss:  tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1150 reconstruct mse: 0.007516777 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1160 , loss:  tensor(0.0065, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1180 , loss:  tensor(0.0066, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.4810850843787266e-06 STD:  7.759863520521375e-08\n",
            "sf: [3. 3.] , iteration:  1200 , loss:  tensor(0.0058, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1200 reconstruct mse: 0.0073661613 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1220 , loss:  tensor(0.0063, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1240 , loss:  tensor(0.0078, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1250 reconstruct mse: 0.0077711055 , true mse: None\n",
            "slope:  -8.691847324371444e-08 STD:  1.124920289725632e-06\n",
            "learning rate updated:  0.0001\n",
            "sf: [3. 3.] , iteration:  1260 , loss:  tensor(0.0117, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1280 , loss:  tensor(0.0054, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1300 , loss:  tensor(0.0056, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1300 reconstruct mse: 0.0074469266 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1320 , loss:  tensor(0.0060, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1340 , loss:  tensor(0.0110, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1350 reconstruct mse: 0.0072664893 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1360 , loss:  tensor(0.0112, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1380 , loss:  tensor(0.0094, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1400 , loss:  tensor(0.0052, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1400 reconstruct mse: 0.0072951065 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1420 , loss:  tensor(0.0087, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1440 , loss:  tensor(0.0094, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1450 reconstruct mse: 0.0072884317 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1460 , loss:  tensor(0.0081, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1480 , loss:  tensor(0.0059, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1500 , loss:  tensor(0.0053, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1500 reconstruct mse: 0.0073163556 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1520 , loss:  tensor(0.0056, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1540 , loss:  tensor(0.0067, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1550 reconstruct mse: 0.007574809 , true mse: None\n",
            "slope:  1.2757759541273075e-06 STD:  5.743783530652228e-07\n",
            "learning rate updated:  1e-05\n",
            "sf: [3. 3.] , iteration:  1560 , loss:  tensor(0.0059, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1580 , loss:  tensor(0.0077, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1600 , loss:  tensor(0.0058, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1600 reconstruct mse: 0.007199817 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1620 , loss:  tensor(0.0083, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1640 , loss:  tensor(0.0093, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1650 reconstruct mse: 0.0068229847 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1660 , loss:  tensor(0.0097, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1680 , loss:  tensor(0.0052, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1700 , loss:  tensor(0.0077, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1700 reconstruct mse: 0.0067713056 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1720 , loss:  tensor(0.0051, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1740 , loss:  tensor(0.0054, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1750 reconstruct mse: 0.0068355566 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1760 , loss:  tensor(0.0103, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1780 , loss:  tensor(0.0094, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1800 , loss:  tensor(0.0058, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1800 reconstruct mse: 0.0068092695 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1820 , loss:  tensor(0.0052, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1840 , loss:  tensor(0.0102, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1850 reconstruct mse: 0.0064040157 , true mse: None\n",
            "slope:  -1.5999479219317367e-06 STD:  9.66358444412087e-07\n",
            "sf: [3. 3.] , iteration:  1860 , loss:  tensor(0.0072, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1880 , loss:  tensor(0.0050, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1900 , loss:  tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1900 reconstruct mse: 0.0065860697 , true mse: None\n",
            "slope:  -1.6040252521633972e-06 STD:  9.654377447159013e-07\n",
            "sf: [3. 3.] , iteration:  1920 , loss:  tensor(0.0107, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1940 , loss:  tensor(0.0057, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1950 reconstruct mse: 0.0063709444 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1960 , loss:  tensor(0.0054, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -2.3048482835292875e-06 STD:  8.758690873815835e-07\n",
            "sf: [3. 3.] , iteration:  1980 , loss:  tensor(0.0053, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  2000 , loss:  tensor(0.0079, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  2000 reconstruct mse: 0.006772673 , true mse: None\n",
            "sf: [3. 3.] , iteration:  2020 , loss:  tensor(0.0056, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -2.125278115272551e-07 STD:  1.473772967991817e-06\n",
            "learning rate updated:  1.0000000000000002e-06\n",
            "** Done training for sf= [3.0, 3.0]  **\n",
            "no kernel loaded\n",
            "['/content/drive/My Drive/DL_visualization/VRDL_HW4/datasets/pytorch-ZSSR/test_data/08_0.mat;']\n",
            "***** 0\n",
            "False\n",
            "** Start training for sf= [3.0, 3.0]  **\n",
            "input shape (130, 195, 3)\n",
            "sf: [3. 3.] , iteration:  0 , loss:  tensor(0.4923, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  0 reconstruct mse: 0.2493476 , true mse: None\n",
            "sf: [3. 3.] , iteration:  20 , loss:  tensor(0.0168, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  40 , loss:  tensor(0.0103, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  50 reconstruct mse: 0.011046763 , true mse: None\n",
            "sf: [3. 3.] , iteration:  60 , loss:  tensor(0.0141, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  80 , loss:  tensor(0.0114, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  100 , loss:  tensor(0.0088, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  100 reconstruct mse: 0.009995208 , true mse: None\n",
            "sf: [3. 3.] , iteration:  120 , loss:  tensor(0.0144, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  140 , loss:  tensor(0.0117, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  150 reconstruct mse: 0.009582823 , true mse: None\n",
            "sf: [3. 3.] , iteration:  160 , loss:  tensor(0.0079, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  180 , loss:  tensor(0.0081, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  200 , loss:  tensor(0.0128, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  200 reconstruct mse: 0.009368167 , true mse: None\n",
            "sf: [3. 3.] , iteration:  220 , loss:  tensor(0.0105, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  240 , loss:  tensor(0.0073, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  250 reconstruct mse: 0.009246968 , true mse: None\n",
            "sf: [3. 3.] , iteration:  260 , loss:  tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  280 , loss:  tensor(0.0100, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -8.453261107206345e-06 STD:  2.1104798087685066e-06\n",
            "sf: [3. 3.] , iteration:  300 , loss:  tensor(0.0108, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  300 reconstruct mse: 0.009010908 , true mse: None\n",
            "sf: [3. 3.] , iteration:  320 , loss:  tensor(0.0089, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  340 , loss:  tensor(0.0133, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  350 reconstruct mse: 0.008966815 , true mse: None\n",
            "slope:  -3.178551793098456e-06 STD:  3.350279984494632e-07\n",
            "sf: [3. 3.] , iteration:  360 , loss:  tensor(0.0127, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  380 , loss:  tensor(0.0098, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  400 , loss:  tensor(0.0106, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  400 reconstruct mse: 0.008618023 , true mse: None\n",
            "slope:  -3.560882061719923e-06 STD:  4.868330822899924e-07\n",
            "sf: [3. 3.] , iteration:  420 , loss:  tensor(0.0102, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  440 , loss:  tensor(0.0124, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  450 reconstruct mse: 0.008651935 , true mse: None\n",
            "sf: [3. 3.] , iteration:  460 , loss:  tensor(0.0114, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -3.1659025698900245e-06 STD:  6.068452628822222e-07\n",
            "sf: [3. 3.] , iteration:  480 , loss:  tensor(0.0110, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  500 , loss:  tensor(0.0110, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  500 reconstruct mse: 0.008901578 , true mse: None\n",
            "sf: [3. 3.] , iteration:  520 , loss:  tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.0670796036720058e-06 STD:  1.181774763383113e-06\n",
            "sf: [3. 3.] , iteration:  540 , loss:  tensor(0.0081, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  550 reconstruct mse: 0.008350689 , true mse: None\n",
            "sf: [3. 3.] , iteration:  560 , loss:  tensor(0.0113, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  580 , loss:  tensor(0.0126, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.8973927944898588e-06 STD:  1.4275671753598056e-06\n",
            "sf: [3. 3.] , iteration:  600 , loss:  tensor(0.0078, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  600 reconstruct mse: 0.008509917 , true mse: None\n",
            "sf: [3. 3.] , iteration:  620 , loss:  tensor(0.0099, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  640 , loss:  tensor(0.0097, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  650 reconstruct mse: 0.008492792 , true mse: None\n",
            "slope:  -1.4198925346136046e-06 STD:  1.2820592413214639e-06\n",
            "sf: [3. 3.] , iteration:  660 , loss:  tensor(0.0081, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  680 , loss:  tensor(0.0092, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  700 , loss:  tensor(0.0121, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  700 reconstruct mse: 0.008826877 , true mse: None\n",
            "slope:  -1.4599412679667113e-08 STD:  1.7237239212456565e-06\n",
            "learning rate updated:  0.0001\n",
            "sf: [3. 3.] , iteration:  720 , loss:  tensor(0.0119, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  740 , loss:  tensor(0.0105, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  750 reconstruct mse: 0.00822792 , true mse: None\n",
            "sf: [3. 3.] , iteration:  760 , loss:  tensor(0.0086, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  780 , loss:  tensor(0.0081, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  800 , loss:  tensor(0.0118, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  800 reconstruct mse: 0.00805019 , true mse: None\n",
            "sf: [3. 3.] , iteration:  820 , loss:  tensor(0.0110, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  840 , loss:  tensor(0.0082, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  850 reconstruct mse: 0.008186471 , true mse: None\n",
            "sf: [3. 3.] , iteration:  860 , loss:  tensor(0.0087, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  880 , loss:  tensor(0.0120, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  900 , loss:  tensor(0.0104, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  900 reconstruct mse: 0.008753003 , true mse: None\n",
            "sf: [3. 3.] , iteration:  920 , loss:  tensor(0.0116, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  940 , loss:  tensor(0.0092, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  950 reconstruct mse: 0.0080074025 , true mse: None\n",
            "sf: [3. 3.] , iteration:  960 , loss:  tensor(0.0111, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  980 , loss:  tensor(0.0080, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1000 , loss:  tensor(0.0115, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1000 reconstruct mse: 0.007953991 , true mse: None\n",
            "slope:  -7.42932781577107e-07 STD:  2.3431437849139008e-06\n",
            "learning rate updated:  1e-05\n",
            "sf: [3. 3.] , iteration:  1020 , loss:  tensor(0.0100, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1040 , loss:  tensor(0.0111, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1050 reconstruct mse: 0.007812562 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1060 , loss:  tensor(0.0108, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1080 , loss:  tensor(0.0102, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1100 , loss:  tensor(0.0077, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1100 reconstruct mse: 0.007907981 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1120 , loss:  tensor(0.0107, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1140 , loss:  tensor(0.0112, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1150 reconstruct mse: 0.007745011 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1160 , loss:  tensor(0.0098, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1180 , loss:  tensor(0.0106, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1200 , loss:  tensor(0.0075, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1200 reconstruct mse: 0.0076390086 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1220 , loss:  tensor(0.0122, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1240 , loss:  tensor(0.0105, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1250 reconstruct mse: 0.007463999 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1260 , loss:  tensor(0.0105, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1280 , loss:  tensor(0.0098, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1300 , loss:  tensor(0.0104, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1300 reconstruct mse: 0.0074948147 , true mse: None\n",
            "slope:  -2.2146888077258987e-06 STD:  3.959731382162084e-07\n",
            "sf: [3. 3.] , iteration:  1320 , loss:  tensor(0.0094, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1340 , loss:  tensor(0.0096, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1350 reconstruct mse: 0.00733692 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1360 , loss:  tensor(0.0084, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.920750364661222e-06 STD:  3.3817877672017476e-07\n",
            "sf: [3. 3.] , iteration:  1380 , loss:  tensor(0.0074, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1400 , loss:  tensor(0.0095, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1400 reconstruct mse: 0.007910679 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1420 , loss:  tensor(0.0079, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  8.325241506099787e-07 STD:  1.526250632607012e-06\n",
            "learning rate updated:  1.0000000000000002e-06\n",
            "** Done training for sf= [3.0, 3.0]  **\n",
            "no kernel loaded\n",
            "['/content/drive/My Drive/DL_visualization/VRDL_HW4/datasets/pytorch-ZSSR/test_data/10_0.mat;']\n",
            "***** 0\n",
            "False\n",
            "** Start training for sf= [3.0, 3.0]  **\n",
            "input shape (96, 117, 3)\n",
            "sf: [3. 3.] , iteration:  0 , loss:  tensor(0.1645, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  0 reconstruct mse: 0.30644628 , true mse: None\n",
            "sf: [3. 3.] , iteration:  20 , loss:  tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  40 , loss:  tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  50 reconstruct mse: 0.0036663334 , true mse: None\n",
            "sf: [3. 3.] , iteration:  60 , loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  80 , loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  100 , loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  100 reconstruct mse: 0.0033293443 , true mse: None\n",
            "sf: [3. 3.] , iteration:  120 , loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  140 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  150 reconstruct mse: 0.0030908547 , true mse: None\n",
            "sf: [3. 3.] , iteration:  160 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  180 , loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  200 , loss:  tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  200 reconstruct mse: 0.0028957487 , true mse: None\n",
            "sf: [3. 3.] , iteration:  220 , loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  240 , loss:  tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  250 reconstruct mse: 0.0029070512 , true mse: None\n",
            "sf: [3. 3.] , iteration:  260 , loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  280 , loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -3.904319833964113e-06 STD:  7.389632398851684e-07\n",
            "sf: [3. 3.] , iteration:  300 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  300 reconstruct mse: 0.002960397 , true mse: None\n",
            "sf: [3. 3.] , iteration:  320 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  340 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  350 reconstruct mse: 0.0029665355 , true mse: None\n",
            "slope:  -3.6798045039176765e-07 STD:  5.244377997333593e-07\n",
            "sf: [3. 3.] , iteration:  360 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  380 , loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  400 , loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  400 reconstruct mse: 0.0029788874 , true mse: None\n",
            "slope:  4.515233449637831e-07 STD:  8.6756583734333e-08\n",
            "learning rate updated:  0.0001\n",
            "sf: [3. 3.] , iteration:  420 , loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  440 , loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  450 reconstruct mse: 0.0029232407 , true mse: None\n",
            "sf: [3. 3.] , iteration:  460 , loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  480 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  500 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  500 reconstruct mse: 0.0027488586 , true mse: None\n",
            "sf: [3. 3.] , iteration:  520 , loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  540 , loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  550 reconstruct mse: 0.002863376 , true mse: None\n",
            "sf: [3. 3.] , iteration:  560 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  580 , loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  600 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  600 reconstruct mse: 0.0028203228 , true mse: None\n",
            "sf: [3. 3.] , iteration:  620 , loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  640 , loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  650 reconstruct mse: 0.0029655485 , true mse: None\n",
            "sf: [3. 3.] , iteration:  660 , loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  680 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  700 , loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  700 reconstruct mse: 0.002935906 , true mse: None\n",
            "slope:  9.525343775749223e-07 STD:  3.250821969322831e-07\n",
            "learning rate updated:  1e-05\n",
            "sf: [3. 3.] , iteration:  720 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  740 , loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  750 reconstruct mse: 0.0030175005 , true mse: None\n",
            "sf: [3. 3.] , iteration:  760 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  780 , loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  800 , loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  800 reconstruct mse: 0.002879549 , true mse: None\n",
            "sf: [3. 3.] , iteration:  820 , loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  840 , loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  850 reconstruct mse: 0.002866879 , true mse: None\n",
            "sf: [3. 3.] , iteration:  860 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  880 , loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  900 , loss:  tensor(0.0010, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  900 reconstruct mse: 0.002844097 , true mse: None\n",
            "sf: [3. 3.] , iteration:  920 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  940 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  950 reconstruct mse: 0.0027533544 , true mse: None\n",
            "sf: [3. 3.] , iteration:  960 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  980 , loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1000 , loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1000 reconstruct mse: 0.0028201675 , true mse: None\n",
            "slope:  -4.6457583084701893e-07 STD:  2.4630343733407356e-07\n",
            "sf: [3. 3.] , iteration:  1020 , loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1040 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1050 reconstruct mse: 0.0027286077 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1060 , loss:  tensor(0.0012, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -6.009447388350941e-07 STD:  2.590764936234914e-07\n",
            "sf: [3. 3.] , iteration:  1080 , loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1100 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1100 reconstruct mse: 0.0027417226 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1120 , loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -4.589911550283391e-07 STD:  2.643812256052498e-07\n",
            "sf: [3. 3.] , iteration:  1140 , loss:  tensor(0.0011, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1150 reconstruct mse: 0.0027614639 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1160 , loss:  tensor(0.0009, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1180 , loss:  tensor(0.0008, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.2445170432329357e-07 STD:  2.47470106456806e-07\n",
            "learning rate updated:  1.0000000000000002e-06\n",
            "** Done training for sf= [3.0, 3.0]  **\n",
            "no kernel loaded\n",
            "['/content/drive/My Drive/DL_visualization/VRDL_HW4/datasets/pytorch-ZSSR/test_data/01_0.mat;']\n",
            "***** 0\n",
            "False\n",
            "** Start training for sf= [3.0, 3.0]  **\n",
            "input shape (170, 170, 3)\n",
            "sf: [3. 3.] , iteration:  0 , loss:  tensor(0.9535, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  0 reconstruct mse: 0.24138749 , true mse: None\n",
            "sf: [3. 3.] , iteration:  20 , loss:  tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  40 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  50 reconstruct mse: 0.0021657073 , true mse: None\n",
            "sf: [3. 3.] , iteration:  60 , loss:  tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  80 , loss:  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  100 , loss:  tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  100 reconstruct mse: 0.001972265 , true mse: None\n",
            "sf: [3. 3.] , iteration:  120 , loss:  tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  140 , loss:  tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  150 reconstruct mse: 0.0019365625 , true mse: None\n",
            "sf: [3. 3.] , iteration:  160 , loss:  tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  180 , loss:  tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  200 , loss:  tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  200 reconstruct mse: 0.0017946007 , true mse: None\n",
            "sf: [3. 3.] , iteration:  220 , loss:  tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  240 , loss:  tensor(0.0024, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  250 reconstruct mse: 0.0016311962 , true mse: None\n",
            "sf: [3. 3.] , iteration:  260 , loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  280 , loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -2.4933728855103292e-06 STD:  2.607976608947596e-07\n",
            "sf: [3. 3.] , iteration:  300 , loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  300 reconstruct mse: 0.0015908444 , true mse: None\n",
            "sf: [3. 3.] , iteration:  320 , loss:  tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  340 , loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  350 reconstruct mse: 0.0015440326 , true mse: None\n",
            "slope:  -1.9776322878897173e-06 STD:  3.288076228033416e-07\n",
            "sf: [3. 3.] , iteration:  360 , loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  380 , loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  400 , loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  400 reconstruct mse: 0.0015609354 , true mse: None\n",
            "slope:  -1.1089886538684418e-06 STD:  3.6296393514688906e-07\n",
            "sf: [3. 3.] , iteration:  420 , loss:  tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  440 , loss:  tensor(0.0023, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  450 reconstruct mse: 0.0014636046 , true mse: None\n",
            "sf: [3. 3.] , iteration:  460 , loss:  tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -7.301843725144894e-07 STD:  1.720979369106742e-07\n",
            "sf: [3. 3.] , iteration:  480 , loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  500 , loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  500 reconstruct mse: 0.0015130535 , true mse: None\n",
            "sf: [3. 3.] , iteration:  520 , loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -4.7201919369399283e-07 STD:  2.274624979307902e-07\n",
            "sf: [3. 3.] , iteration:  540 , loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  550 reconstruct mse: 0.0013890568 , true mse: None\n",
            "sf: [3. 3.] , iteration:  560 , loss:  tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  580 , loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -7.156669162213831e-07 STD:  2.939167664219255e-07\n",
            "sf: [3. 3.] , iteration:  600 , loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  600 reconstruct mse: 0.0013376944 , true mse: None\n",
            "sf: [3. 3.] , iteration:  620 , loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  640 , loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  650 reconstruct mse: 0.0013504855 , true mse: None\n",
            "slope:  -8.031949400901769e-07 STD:  2.959978453637025e-07\n",
            "sf: [3. 3.] , iteration:  660 , loss:  tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  680 , loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  700 , loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  700 reconstruct mse: 0.0013199532 , true mse: None\n",
            "slope:  -8.495438378304224e-07 STD:  2.8255159974050095e-07\n",
            "sf: [3. 3.] , iteration:  720 , loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  740 , loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  750 reconstruct mse: 0.0013507264 , true mse: None\n",
            "sf: [3. 3.] , iteration:  760 , loss:  tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.888039987534296e-07 STD:  1.5003959113251334e-07\n",
            "sf: [3. 3.] , iteration:  780 , loss:  tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  800 , loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  800 reconstruct mse: 0.0012870625 , true mse: None\n",
            "sf: [3. 3.] , iteration:  820 , loss:  tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -2.0204554311931154e-07 STD:  1.5616730030121656e-07\n",
            "sf: [3. 3.] , iteration:  840 , loss:  tensor(0.0021, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  850 reconstruct mse: 0.0013224648 , true mse: None\n",
            "sf: [3. 3.] , iteration:  860 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  880 , loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.7786421813070685e-07 STD:  1.6269114832435874e-07\n",
            "sf: [3. 3.] , iteration:  900 , loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  900 reconstruct mse: 0.0013373523 , true mse: None\n",
            "sf: [3. 3.] , iteration:  920 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  940 , loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  950 reconstruct mse: 0.0012921618 , true mse: None\n",
            "slope:  -1.3367878273129563e-07 STD:  1.8773885795419659e-07\n",
            "sf: [3. 3.] , iteration:  960 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  980 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1000 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1000 reconstruct mse: 0.0012742155 , true mse: None\n",
            "slope:  -1.1199410073458927e-07 STD:  1.805473816654204e-07\n",
            "learning rate updated:  0.0001\n",
            "sf: [3. 3.] , iteration:  1020 , loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1040 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1050 reconstruct mse: 0.0013193047 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1060 , loss:  tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1080 , loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1100 , loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1100 reconstruct mse: 0.0013067801 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1120 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1140 , loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1150 reconstruct mse: 0.0012693332 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1160 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1180 , loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1200 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1200 reconstruct mse: 0.0012732757 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1220 , loss:  tensor(0.0022, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1240 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1250 reconstruct mse: 0.0012241037 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1260 , loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1280 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1300 , loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1300 reconstruct mse: 0.0012211923 , true mse: None\n",
            "slope:  -4.3281028047204054e-07 STD:  8.622034051472538e-08\n",
            "sf: [3. 3.] , iteration:  1320 , loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1340 , loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1350 reconstruct mse: 0.0012405413 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1360 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -2.1933414973318649e-07 STD:  1.2701165446106654e-07\n",
            "sf: [3. 3.] , iteration:  1380 , loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1400 , loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1400 reconstruct mse: 0.0012165934 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1420 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.9385386258363716e-07 STD:  1.2671942574392595e-07\n",
            "sf: [3. 3.] , iteration:  1440 , loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1450 reconstruct mse: 0.0012008316 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1460 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1480 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.0228622704744194e-07 STD:  8.606589275025115e-08\n",
            "sf: [3. 3.] , iteration:  1500 , loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1500 reconstruct mse: 0.0012124241 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1520 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1540 , loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1550 reconstruct mse: 0.0011738851 , true mse: None\n",
            "slope:  -2.749636769294749e-07 STD:  7.948092660445528e-08\n",
            "sf: [3. 3.] , iteration:  1560 , loss:  tensor(0.0013, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1580 , loss:  tensor(0.0020, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1600 , loss:  tensor(0.0015, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1600 reconstruct mse: 0.0012651049 , true mse: None\n",
            "slope:  1.401526387780907e-07 STD:  2.2839121866186688e-07\n",
            "learning rate updated:  1e-05\n",
            "sf: [3. 3.] , iteration:  1620 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1640 , loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1650 reconstruct mse: 0.0012018653 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1660 , loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1680 , loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1700 , loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1700 reconstruct mse: 0.0011716334 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1720 , loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1740 , loss:  tensor(0.0016, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1750 reconstruct mse: 0.0012093291 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1760 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1780 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1800 , loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1800 reconstruct mse: 0.001158437 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1820 , loss:  tensor(0.0019, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1840 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1850 reconstruct mse: 0.0012008493 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1860 , loss:  tensor(0.0017, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1880 , loss:  tensor(0.0014, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1900 , loss:  tensor(0.0018, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1900 reconstruct mse: 0.0012614949 , true mse: None\n",
            "slope:  3.424866590648885e-07 STD:  2.1505020994263322e-07\n",
            "learning rate updated:  1.0000000000000002e-06\n",
            "** Done training for sf= [3.0, 3.0]  **\n",
            "no kernel loaded\n",
            "['/content/drive/My Drive/DL_visualization/VRDL_HW4/datasets/pytorch-ZSSR/test_data/12_0.mat;']\n",
            "***** 0\n",
            "False\n",
            "** Start training for sf= [3.0, 3.0]  **\n",
            "input shape (120, 166, 3)\n",
            "sf: [3. 3.] , iteration:  0 , loss:  tensor(1.6915, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  0 reconstruct mse: 0.10834686 , true mse: None\n",
            "sf: [3. 3.] , iteration:  20 , loss:  tensor(0.0079, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  40 , loss:  tensor(0.0081, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  50 reconstruct mse: 0.0058300146 , true mse: None\n",
            "sf: [3. 3.] , iteration:  60 , loss:  tensor(0.0071, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  80 , loss:  tensor(0.0056, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  100 , loss:  tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  100 reconstruct mse: 0.005317555 , true mse: None\n",
            "sf: [3. 3.] , iteration:  120 , loss:  tensor(0.0057, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  140 , loss:  tensor(0.0058, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  150 reconstruct mse: 0.005059584 , true mse: None\n",
            "sf: [3. 3.] , iteration:  160 , loss:  tensor(0.0062, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  180 , loss:  tensor(0.0052, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  200 , loss:  tensor(0.0057, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  200 reconstruct mse: 0.004853536 , true mse: None\n",
            "sf: [3. 3.] , iteration:  220 , loss:  tensor(0.0057, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  240 , loss:  tensor(0.0055, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  250 reconstruct mse: 0.0047162287 , true mse: None\n",
            "sf: [3. 3.] , iteration:  260 , loss:  tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  280 , loss:  tensor(0.0056, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -5.3831813856959385e-06 STD:  8.17370118434627e-07\n",
            "sf: [3. 3.] , iteration:  300 , loss:  tensor(0.0055, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  300 reconstruct mse: 0.0045917374 , true mse: None\n",
            "sf: [3. 3.] , iteration:  320 , loss:  tensor(0.0060, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  340 , loss:  tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  350 reconstruct mse: 0.004515505 , true mse: None\n",
            "slope:  -2.6999134570360207e-06 STD:  2.6989317371498063e-07\n",
            "sf: [3. 3.] , iteration:  360 , loss:  tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  380 , loss:  tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  400 , loss:  tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  400 reconstruct mse: 0.004423644 , true mse: None\n",
            "slope:  -2.1210154518485224e-06 STD:  1.4628441254104338e-07\n",
            "sf: [3. 3.] , iteration:  420 , loss:  tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  440 , loss:  tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  450 reconstruct mse: 0.004329498 , true mse: None\n",
            "sf: [3. 3.] , iteration:  460 , loss:  tensor(0.0053, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.8831100314855632e-06 STD:  8.047511166164225e-08\n",
            "sf: [3. 3.] , iteration:  480 , loss:  tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  500 , loss:  tensor(0.0052, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  500 reconstruct mse: 0.00429536 , true mse: None\n",
            "sf: [3. 3.] , iteration:  520 , loss:  tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.5575243160128533e-06 STD:  1.203037945794822e-07\n",
            "sf: [3. 3.] , iteration:  540 , loss:  tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  550 reconstruct mse: 0.0042272406 , true mse: None\n",
            "sf: [3. 3.] , iteration:  560 , loss:  tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  580 , loss:  tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.4096256345510418e-06 STD:  1.3036840121275744e-07\n",
            "sf: [3. 3.] , iteration:  600 , loss:  tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  600 reconstruct mse: 0.004126888 , true mse: None\n",
            "sf: [3. 3.] , iteration:  620 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  640 , loss:  tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  650 reconstruct mse: 0.0041060005 , true mse: None\n",
            "slope:  -1.2309337034821436e-06 STD:  1.3962174894987187e-07\n",
            "sf: [3. 3.] , iteration:  660 , loss:  tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  680 , loss:  tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  700 , loss:  tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  700 reconstruct mse: 0.0041171587 , true mse: None\n",
            "slope:  -9.552845731377558e-07 STD:  2.535500589880019e-07\n",
            "sf: [3. 3.] , iteration:  720 , loss:  tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  740 , loss:  tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  750 reconstruct mse: 0.0040092133 , true mse: None\n",
            "sf: [3. 3.] , iteration:  760 , loss:  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -8.91567207872869e-07 STD:  2.3429283784051856e-07\n",
            "sf: [3. 3.] , iteration:  780 , loss:  tensor(0.0036, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  800 , loss:  tensor(0.0050, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  800 reconstruct mse: 0.003977407 , true mse: None\n",
            "sf: [3. 3.] , iteration:  820 , loss:  tensor(0.0050, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -7.914984598755828e-07 STD:  2.1063177289036606e-07\n",
            "sf: [3. 3.] , iteration:  840 , loss:  tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  850 reconstruct mse: 0.003948006 , true mse: None\n",
            "sf: [3. 3.] , iteration:  860 , loss:  tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  880 , loss:  tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -9.11482609808447e-07 STD:  1.8300314839781238e-07\n",
            "sf: [3. 3.] , iteration:  900 , loss:  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  900 reconstruct mse: 0.004045589 , true mse: None\n",
            "sf: [3. 3.] , iteration:  920 , loss:  tensor(0.0039, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  940 , loss:  tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  950 reconstruct mse: 0.0038483695 , true mse: None\n",
            "slope:  -5.07011078298096e-07 STD:  4.628278472324064e-07\n",
            "sf: [3. 3.] , iteration:  960 , loss:  tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  980 , loss:  tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1000 , loss:  tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1000 reconstruct mse: 0.0039030542 , true mse: None\n",
            "slope:  -4.966831766068925e-07 STD:  4.6340180386818194e-07\n",
            "sf: [3. 3.] , iteration:  1020 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1040 , loss:  tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1050 reconstruct mse: 0.0038111263 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1060 , loss:  tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -8.325874805450415e-07 STD:  4.635193098872798e-07\n",
            "sf: [3. 3.] , iteration:  1080 , loss:  tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1100 , loss:  tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1100 reconstruct mse: 0.0038934413 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1120 , loss:  tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -6.830766797065672e-07 STD:  5.1829678949844e-07\n",
            "sf: [3. 3.] , iteration:  1140 , loss:  tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1150 reconstruct mse: 0.0038336967 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1160 , loss:  tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1180 , loss:  tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -7.791677489876864e-08 STD:  2.831890899492476e-07\n",
            "learning rate updated:  0.0001\n",
            "sf: [3. 3.] , iteration:  1200 , loss:  tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1200 reconstruct mse: 0.0037889688 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1220 , loss:  tensor(0.0036, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1240 , loss:  tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1250 reconstruct mse: 0.0038054811 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1260 , loss:  tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1280 , loss:  tensor(0.0039, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1300 , loss:  tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1300 reconstruct mse: 0.0037185054 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1320 , loss:  tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1340 , loss:  tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1350 reconstruct mse: 0.0037757019 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1360 , loss:  tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1380 , loss:  tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1400 , loss:  tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1400 reconstruct mse: 0.0037976364 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1420 , loss:  tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1440 , loss:  tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1450 reconstruct mse: 0.0036434005 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1460 , loss:  tensor(0.0039, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1480 , loss:  tensor(0.0036, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -4.900605417788062e-07 STD:  4.0566227907014227e-07\n",
            "sf: [3. 3.] , iteration:  1500 , loss:  tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1500 reconstruct mse: 0.0037962466 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1520 , loss:  tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1540 , loss:  tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1550 reconstruct mse: 0.0036428645 , true mse: None\n",
            "slope:  -5.341288633644619e-07 STD:  5.033862543135139e-07\n",
            "sf: [3. 3.] , iteration:  1560 , loss:  tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1580 , loss:  tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1600 , loss:  tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1600 reconstruct mse: 0.0036758475 , true mse: None\n",
            "slope:  -4.882272332906764e-07 STD:  5.067718649447354e-07\n",
            "sf: [3. 3.] , iteration:  1620 , loss:  tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1640 , loss:  tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1650 reconstruct mse: 0.0036374852 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1660 , loss:  tensor(0.0036, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -2.644592896103815e-07 STD:  4.6625698082730984e-07\n",
            "learning rate updated:  1e-05\n",
            "sf: [3. 3.] , iteration:  1680 , loss:  tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1700 , loss:  tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1700 reconstruct mse: 0.0037405645 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1720 , loss:  tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1740 , loss:  tensor(0.0036, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1750 reconstruct mse: 0.003657196 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1760 , loss:  tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1780 , loss:  tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1800 , loss:  tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1800 reconstruct mse: 0.0036819712 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1820 , loss:  tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1840 , loss:  tensor(0.0039, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1850 reconstruct mse: 0.0036280043 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1860 , loss:  tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1880 , loss:  tensor(0.0039, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1900 , loss:  tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1900 reconstruct mse: 0.0036500418 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1920 , loss:  tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1940 , loss:  tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1950 reconstruct mse: 0.0036643026 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1960 , loss:  tensor(0.0034, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -3.543216735125025e-08 STD:  1.4293497686885492e-07\n",
            "learning rate updated:  1.0000000000000002e-06\n",
            "** Done training for sf= [3.0, 3.0]  **\n",
            "no kernel loaded\n",
            "['/content/drive/My Drive/DL_visualization/VRDL_HW4/datasets/pytorch-ZSSR/test_data/13_0.mat;']\n",
            "***** 0\n",
            "False\n",
            "** Start training for sf= [3.0, 3.0]  **\n",
            "input shape (170, 170, 3)\n",
            "sf: [3. 3.] , iteration:  0 , loss:  tensor(0.5947, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  0 reconstruct mse: 0.21257919 , true mse: None\n",
            "sf: [3. 3.] , iteration:  20 , loss:  tensor(0.0051, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  40 , loss:  tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  50 reconstruct mse: 0.003847869 , true mse: None\n",
            "sf: [3. 3.] , iteration:  60 , loss:  tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  80 , loss:  tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  100 , loss:  tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  100 reconstruct mse: 0.003174947 , true mse: None\n",
            "sf: [3. 3.] , iteration:  120 , loss:  tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  140 , loss:  tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  150 reconstruct mse: 0.0030513632 , true mse: None\n",
            "sf: [3. 3.] , iteration:  160 , loss:  tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  180 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  200 , loss:  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  200 reconstruct mse: 0.0029736392 , true mse: None\n",
            "sf: [3. 3.] , iteration:  220 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  240 , loss:  tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  250 reconstruct mse: 0.0029414173 , true mse: None\n",
            "sf: [3. 3.] , iteration:  260 , loss:  tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  280 , loss:  tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -4.028423223644492e-06 STD:  1.4368074711754104e-06\n",
            "sf: [3. 3.] , iteration:  300 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  300 reconstruct mse: 0.002995226 , true mse: None\n",
            "sf: [3. 3.] , iteration:  320 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  340 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  350 reconstruct mse: 0.002904751 , true mse: None\n",
            "slope:  -5.432744510471846e-07 STD:  2.559037283027378e-07\n",
            "sf: [3. 3.] , iteration:  360 , loss:  tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  380 , loss:  tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  400 , loss:  tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  400 reconstruct mse: 0.0028674183 , true mse: None\n",
            "slope:  -4.982156679034304e-07 STD:  2.42955272080174e-07\n",
            "sf: [3. 3.] , iteration:  420 , loss:  tensor(0.0034, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  440 , loss:  tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  450 reconstruct mse: 0.0028289834 , true mse: None\n",
            "sf: [3. 3.] , iteration:  460 , loss:  tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -7.053511217236559e-07 STD:  2.362817701441292e-07\n",
            "sf: [3. 3.] , iteration:  480 , loss:  tensor(0.0036, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  500 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  500 reconstruct mse: 0.002874574 , true mse: None\n",
            "sf: [3. 3.] , iteration:  520 , loss:  tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -6.341440603136994e-07 STD:  2.737340512608879e-07\n",
            "sf: [3. 3.] , iteration:  540 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  550 reconstruct mse: 0.0028114563 , true mse: None\n",
            "sf: [3. 3.] , iteration:  560 , loss:  tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  580 , loss:  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -3.588679246604469e-07 STD:  1.764880687813734e-07\n",
            "sf: [3. 3.] , iteration:  600 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  600 reconstruct mse: 0.0027767536 , true mse: None\n",
            "sf: [3. 3.] , iteration:  620 , loss:  tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  640 , loss:  tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  650 reconstruct mse: 0.0027779674 , true mse: None\n",
            "slope:  -3.997045569121792e-07 STD:  1.8589270611911867e-07\n",
            "sf: [3. 3.] , iteration:  660 , loss:  tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  680 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  700 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  700 reconstruct mse: 0.002739948 , true mse: None\n",
            "slope:  -6.054816767573396e-07 STD:  1.2027122351874645e-07\n",
            "sf: [3. 3.] , iteration:  720 , loss:  tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  740 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  750 reconstruct mse: 0.0027553379 , true mse: None\n",
            "sf: [3. 3.] , iteration:  760 , loss:  tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -2.980851568281656e-07 STD:  9.648279666233096e-08\n",
            "sf: [3. 3.] , iteration:  780 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  800 , loss:  tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  800 reconstruct mse: 0.0027625947 , true mse: None\n",
            "sf: [3. 3.] , iteration:  820 , loss:  tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.0189460590482047e-07 STD:  9.951475081604476e-08\n",
            "sf: [3. 3.] , iteration:  840 , loss:  tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  850 reconstruct mse: 0.0027029319 , true mse: None\n",
            "sf: [3. 3.] , iteration:  860 , loss:  tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  880 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -2.5484850630164094e-07 STD:  1.477327571959145e-07\n",
            "sf: [3. 3.] , iteration:  900 , loss:  tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  900 reconstruct mse: 0.0027682097 , true mse: None\n",
            "sf: [3. 3.] , iteration:  920 , loss:  tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  940 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  950 reconstruct mse: 0.0027255623 , true mse: None\n",
            "slope:  -1.0787229984998956e-07 STD:  1.9288317502520664e-07\n",
            "learning rate updated:  0.0001\n",
            "sf: [3. 3.] , iteration:  960 , loss:  tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  980 , loss:  tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1000 , loss:  tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1000 reconstruct mse: 0.0027127785 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1020 , loss:  tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1040 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1050 reconstruct mse: 0.002741072 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1060 , loss:  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1080 , loss:  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1100 , loss:  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1100 reconstruct mse: 0.0026948787 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1120 , loss:  tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1140 , loss:  tensor(0.0034, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1150 reconstruct mse: 0.0026490404 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1160 , loss:  tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1180 , loss:  tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1200 , loss:  tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1200 reconstruct mse: 0.0026731014 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1220 , loss:  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1240 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1250 reconstruct mse: 0.0026872912 , true mse: None\n",
            "slope:  -2.5867810472845595e-07 STD:  1.9750535457781671e-07\n",
            "sf: [3. 3.] , iteration:  1260 , loss:  tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1280 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1300 , loss:  tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1300 reconstruct mse: 0.0026693728 , true mse: None\n",
            "slope:  -2.552196383476596e-08 STD:  1.2851860345426155e-07\n",
            "learning rate updated:  1e-05\n",
            "sf: [3. 3.] , iteration:  1320 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1340 , loss:  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1350 reconstruct mse: 0.0026675551 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1360 , loss:  tensor(0.0034, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1380 , loss:  tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1400 , loss:  tensor(0.0034, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1400 reconstruct mse: 0.0026372268 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1420 , loss:  tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1440 , loss:  tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1450 reconstruct mse: 0.0025486522 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1460 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1480 , loss:  tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1500 , loss:  tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1500 reconstruct mse: 0.0026558866 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1520 , loss:  tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1540 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1550 reconstruct mse: 0.002588928 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1560 , loss:  tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1580 , loss:  tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1600 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1600 reconstruct mse: 0.0025898723 , true mse: None\n",
            "slope:  -1.088664866983948e-07 STD:  3.052869544036424e-07\n",
            "learning rate updated:  1.0000000000000002e-06\n",
            "** Done training for sf= [3.0, 3.0]  **\n",
            "no kernel loaded\n",
            "['/content/drive/My Drive/DL_visualization/VRDL_HW4/datasets/pytorch-ZSSR/test_data/04_0.mat;']\n",
            "***** 0\n",
            "False\n",
            "** Start training for sf= [3.0, 3.0]  **\n",
            "input shape (170, 256, 3)\n",
            "sf: [3. 3.] , iteration:  0 , loss:  tensor(0.0464, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  0 reconstruct mse: 0.18439034 , true mse: None\n",
            "sf: [3. 3.] , iteration:  20 , loss:  tensor(0.0053, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  40 , loss:  tensor(0.0089, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  50 reconstruct mse: 0.004706318 , true mse: None\n",
            "sf: [3. 3.] , iteration:  60 , loss:  tensor(0.0065, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  80 , loss:  tensor(0.0083, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  100 , loss:  tensor(0.0063, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  100 reconstruct mse: 0.0041143512 , true mse: None\n",
            "sf: [3. 3.] , iteration:  120 , loss:  tensor(0.0071, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  140 , loss:  tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  150 reconstruct mse: 0.003725274 , true mse: None\n",
            "sf: [3. 3.] , iteration:  160 , loss:  tensor(0.0052, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  180 , loss:  tensor(0.0058, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  200 , loss:  tensor(0.0066, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  200 reconstruct mse: 0.0035142913 , true mse: None\n",
            "sf: [3. 3.] , iteration:  220 , loss:  tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  240 , loss:  tensor(0.0084, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  250 reconstruct mse: 0.0033416385 , true mse: None\n",
            "sf: [3. 3.] , iteration:  260 , loss:  tensor(0.0078, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  280 , loss:  tensor(0.0076, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -6.6588381305336915e-06 STD:  1.0114958683435274e-06\n",
            "sf: [3. 3.] , iteration:  300 , loss:  tensor(0.0063, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  300 reconstruct mse: 0.0038924427 , true mse: None\n",
            "sf: [3. 3.] , iteration:  320 , loss:  tensor(0.0060, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  340 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  350 reconstruct mse: 0.003224505 , true mse: None\n",
            "slope:  -1.246772706508635e-06 STD:  1.859124574099575e-06\n",
            "sf: [3. 3.] , iteration:  360 , loss:  tensor(0.0039, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  380 , loss:  tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  400 , loss:  tensor(0.0039, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  400 reconstruct mse: 0.003168642 , true mse: None\n",
            "slope:  -1.6168635338544956e-06 STD:  1.9111307348691546e-06\n",
            "sf: [3. 3.] , iteration:  420 , loss:  tensor(0.0062, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  440 , loss:  tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  450 reconstruct mse: 0.003202318 , true mse: None\n",
            "sf: [3. 3.] , iteration:  460 , loss:  tensor(0.0056, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -2.0048832520842547e-06 STD:  1.8726422632509928e-06\n",
            "sf: [3. 3.] , iteration:  480 , loss:  tensor(0.0057, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  500 , loss:  tensor(0.0059, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  500 reconstruct mse: 0.003146193 , true mse: None\n",
            "sf: [3. 3.] , iteration:  520 , loss:  tensor(0.0055, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -3.0293730087578184e-06 STD:  1.5236664562882023e-06\n",
            "sf: [3. 3.] , iteration:  540 , loss:  tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  550 reconstruct mse: 0.0029867669 , true mse: None\n",
            "sf: [3. 3.] , iteration:  560 , loss:  tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  580 , loss:  tensor(0.0058, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -9.958511218428608e-07 STD:  3.725439861491763e-07\n",
            "sf: [3. 3.] , iteration:  600 , loss:  tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  600 reconstruct mse: 0.0031112505 , true mse: None\n",
            "sf: [3. 3.] , iteration:  620 , loss:  tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  640 , loss:  tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  650 reconstruct mse: 0.0029748988 , true mse: None\n",
            "slope:  -9.795618243515476e-07 STD:  4.6156424603300253e-07\n",
            "sf: [3. 3.] , iteration:  660 , loss:  tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  680 , loss:  tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  700 , loss:  tensor(0.0050, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  700 reconstruct mse: 0.0028838194 , true mse: None\n",
            "slope:  -1.073230523616075e-06 STD:  4.780198931822611e-07\n",
            "sf: [3. 3.] , iteration:  720 , loss:  tensor(0.0047, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  740 , loss:  tensor(0.0054, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  750 reconstruct mse: 0.0029224833 , true mse: None\n",
            "sf: [3. 3.] , iteration:  760 , loss:  tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -7.119965739548246e-07 STD:  4.774589958562355e-07\n",
            "sf: [3. 3.] , iteration:  780 , loss:  tensor(0.0052, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  800 , loss:  tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  800 reconstruct mse: 0.0028202736 , true mse: None\n",
            "sf: [3. 3.] , iteration:  820 , loss:  tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.268738415092236e-06 STD:  3.2797013877583423e-07\n",
            "sf: [3. 3.] , iteration:  840 , loss:  tensor(0.0053, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  850 reconstruct mse: 0.002913661 , true mse: None\n",
            "sf: [3. 3.] , iteration:  860 , loss:  tensor(0.0034, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  880 , loss:  tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -3.7204241380095854e-07 STD:  3.542851316207299e-07\n",
            "sf: [3. 3.] , iteration:  900 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  900 reconstruct mse: 0.0028931084 , true mse: None\n",
            "sf: [3. 3.] , iteration:  920 , loss:  tensor(0.0036, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  940 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  950 reconstruct mse: 0.0028110868 , true mse: None\n",
            "slope:  -2.999161370098599e-07 STD:  3.438407167450914e-07\n",
            "sf: [3. 3.] , iteration:  960 , loss:  tensor(0.0047, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  980 , loss:  tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1000 , loss:  tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1000 reconstruct mse: 0.0026924768 , true mse: None\n",
            "slope:  -7.16335605829953e-07 STD:  4.822604670757662e-07\n",
            "sf: [3. 3.] , iteration:  1020 , loss:  tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1040 , loss:  tensor(0.0068, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1050 reconstruct mse: 0.0026217871 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1060 , loss:  tensor(0.0047, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.568758860230442e-06 STD:  1.8566442633752262e-07\n",
            "sf: [3. 3.] , iteration:  1080 , loss:  tensor(0.0062, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1100 , loss:  tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1100 reconstruct mse: 0.0027159813 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1120 , loss:  tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.087107695639131e-06 STD:  4.549408964725241e-07\n",
            "sf: [3. 3.] , iteration:  1140 , loss:  tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1150 reconstruct mse: 0.0026181869 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1160 , loss:  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1180 , loss:  tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -7.245908491313488e-07 STD:  4.001563857168043e-07\n",
            "sf: [3. 3.] , iteration:  1200 , loss:  tensor(0.0063, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1200 reconstruct mse: 0.0025749328 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1220 , loss:  tensor(0.0064, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1240 , loss:  tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1250 reconstruct mse: 0.002672043 , true mse: None\n",
            "slope:  -8.10739584267142e-08 STD:  3.945484487970001e-07\n",
            "learning rate updated:  0.0001\n",
            "sf: [3. 3.] , iteration:  1260 , loss:  tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1280 , loss:  tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1300 , loss:  tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1300 reconstruct mse: 0.0025913082 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1320 , loss:  tensor(0.0053, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1340 , loss:  tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1350 reconstruct mse: 0.0025224383 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1360 , loss:  tensor(0.0050, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1380 , loss:  tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1400 , loss:  tensor(0.0050, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1400 reconstruct mse: 0.0025070067 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1420 , loss:  tensor(0.0039, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1440 , loss:  tensor(0.0050, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1450 reconstruct mse: 0.0024821 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1460 , loss:  tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1480 , loss:  tensor(0.0030, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1500 , loss:  tensor(0.0060, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1500 reconstruct mse: 0.0025275592 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1520 , loss:  tensor(0.0052, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1540 , loss:  tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1550 reconstruct mse: 0.0024099466 , true mse: None\n",
            "slope:  -4.088617861270922e-07 STD:  2.593257169101801e-07\n",
            "sf: [3. 3.] , iteration:  1560 , loss:  tensor(0.0059, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1580 , loss:  tensor(0.0039, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1600 , loss:  tensor(0.0050, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1600 reconstruct mse: 0.0025366934 , true mse: None\n",
            "slope:  -2.556014806032344e-08 STD:  3.705743345794269e-07\n",
            "learning rate updated:  1e-05\n",
            "sf: [3. 3.] , iteration:  1620 , loss:  tensor(0.0055, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1640 , loss:  tensor(0.0060, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1650 reconstruct mse: 0.0024119131 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1660 , loss:  tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1680 , loss:  tensor(0.0055, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1700 , loss:  tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1700 reconstruct mse: 0.0023781 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1720 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1740 , loss:  tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1750 reconstruct mse: 0.0023682695 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1760 , loss:  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1780 , loss:  tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1800 , loss:  tensor(0.0063, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1800 reconstruct mse: 0.0024623808 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1820 , loss:  tensor(0.0068, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1840 , loss:  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1850 reconstruct mse: 0.002343189 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1860 , loss:  tensor(0.0066, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1880 , loss:  tensor(0.0074, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1900 , loss:  tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1900 reconstruct mse: 0.0022715428 , true mse: None\n",
            "slope:  -4.763901233673036e-07 STD:  4.195416934812876e-07\n",
            "sf: [3. 3.] , iteration:  1920 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1940 , loss:  tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1950 reconstruct mse: 0.0022079959 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1960 , loss:  tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.0227705352008403e-06 STD:  3.8835830835010706e-07\n",
            "sf: [3. 3.] , iteration:  1980 , loss:  tensor(0.0056, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  2000 , loss:  tensor(0.0050, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  2000 reconstruct mse: 0.0022753119 , true mse: None\n",
            "sf: [3. 3.] , iteration:  2020 , loss:  tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.0186620056629204e-06 STD:  3.906398423915857e-07\n",
            "sf: [3. 3.] , iteration:  2040 , loss:  tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  2050 reconstruct mse: 0.0021536143 , true mse: None\n",
            "sf: [3. 3.] , iteration:  2060 , loss:  tensor(0.0047, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  2080 , loss:  tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -7.507605478167506e-07 STD:  3.0004298965456183e-07\n",
            "sf: [3. 3.] , iteration:  2100 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  2100 reconstruct mse: 0.002279896 , true mse: None\n",
            "sf: [3. 3.] , iteration:  2120 , loss:  tensor(0.0026, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  2140 , loss:  tensor(0.0052, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  2150 reconstruct mse: 0.0022923222 , true mse: None\n",
            "slope:  3.4647388383746334e-07 STD:  3.837564983203481e-07\n",
            "learning rate updated:  1.0000000000000002e-06\n",
            "** Done training for sf= [3.0, 3.0]  **\n",
            "no kernel loaded\n",
            "['/content/drive/My Drive/DL_visualization/VRDL_HW4/datasets/pytorch-ZSSR/test_data/07_0.mat;']\n",
            "***** 0\n",
            "False\n",
            "** Start training for sf= [3.0, 3.0]  **\n",
            "input shape (170, 170, 3)\n",
            "sf: [3. 3.] , iteration:  0 , loss:  tensor(0.2639, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  0 reconstruct mse: 0.22148764 , true mse: None\n",
            "sf: [3. 3.] , iteration:  20 , loss:  tensor(0.0057, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  40 , loss:  tensor(0.0048, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  50 reconstruct mse: 0.004252107 , true mse: None\n",
            "sf: [3. 3.] , iteration:  60 , loss:  tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  80 , loss:  tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  100 , loss:  tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  100 reconstruct mse: 0.004027304 , true mse: None\n",
            "sf: [3. 3.] , iteration:  120 , loss:  tensor(0.0050, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  140 , loss:  tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  150 reconstruct mse: 0.003924613 , true mse: None\n",
            "sf: [3. 3.] , iteration:  160 , loss:  tensor(0.0046, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  180 , loss:  tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  200 , loss:  tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  200 reconstruct mse: 0.0038506503 , true mse: None\n",
            "sf: [3. 3.] , iteration:  220 , loss:  tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  240 , loss:  tensor(0.0036, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  250 reconstruct mse: 0.003817787 , true mse: None\n",
            "sf: [3. 3.] , iteration:  260 , loss:  tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  280 , loss:  tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -2.090586815029384e-06 STD:  4.1595599066624646e-07\n",
            "sf: [3. 3.] , iteration:  300 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  300 reconstruct mse: 0.0037379307 , true mse: None\n",
            "sf: [3. 3.] , iteration:  320 , loss:  tensor(0.0039, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  340 , loss:  tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  350 reconstruct mse: 0.0037042578 , true mse: None\n",
            "slope:  -1.1068596504628655e-06 STD:  8.583422843610733e-08\n",
            "sf: [3. 3.] , iteration:  360 , loss:  tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  380 , loss:  tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  400 , loss:  tensor(0.0035, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  400 reconstruct mse: 0.0036781032 , true mse: None\n",
            "slope:  -9.172465652227527e-07 STD:  1.0322771890020868e-07\n",
            "sf: [3. 3.] , iteration:  420 , loss:  tensor(0.0039, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  440 , loss:  tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  450 reconstruct mse: 0.0036678845 , true mse: None\n",
            "sf: [3. 3.] , iteration:  460 , loss:  tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -7.192646153271299e-07 STD:  1.4887687763708873e-07\n",
            "sf: [3. 3.] , iteration:  480 , loss:  tensor(0.0036, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  500 , loss:  tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  500 reconstruct mse: 0.0036609643 , true mse: None\n",
            "sf: [3. 3.] , iteration:  520 , loss:  tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -3.8061197847126986e-07 STD:  6.856128106961217e-08\n",
            "sf: [3. 3.] , iteration:  540 , loss:  tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  550 reconstruct mse: 0.0036729171 , true mse: None\n",
            "sf: [3. 3.] , iteration:  560 , loss:  tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  580 , loss:  tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -1.5964033082127933e-07 STD:  7.864097713556965e-08\n",
            "sf: [3. 3.] , iteration:  600 , loss:  tensor(0.0031, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  600 reconstruct mse: 0.0036606782 , true mse: None\n",
            "sf: [3. 3.] , iteration:  620 , loss:  tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  640 , loss:  tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  650 reconstruct mse: 0.0036293215 , true mse: None\n",
            "slope:  -1.5482446178793113e-07 STD:  8.631367733609862e-08\n",
            "sf: [3. 3.] , iteration:  660 , loss:  tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  680 , loss:  tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  700 , loss:  tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  700 reconstruct mse: 0.003646213 , true mse: None\n",
            "slope:  -1.461962237954144e-07 STD:  8.841482170607266e-08\n",
            "sf: [3. 3.] , iteration:  720 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  740 , loss:  tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  750 reconstruct mse: 0.003614414 , true mse: None\n",
            "sf: [3. 3.] , iteration:  760 , loss:  tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -2.629426307976292e-07 STD:  7.992223200716827e-08\n",
            "sf: [3. 3.] , iteration:  780 , loss:  tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  800 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  800 reconstruct mse: 0.0037193517 , true mse: None\n",
            "sf: [3. 3.] , iteration:  820 , loss:  tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  2.048793248832203e-07 STD:  2.7086952878106716e-07\n",
            "learning rate updated:  0.0001\n",
            "sf: [3. 3.] , iteration:  840 , loss:  tensor(0.0049, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  850 reconstruct mse: 0.003654693 , true mse: None\n",
            "sf: [3. 3.] , iteration:  860 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  880 , loss:  tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  900 , loss:  tensor(0.0039, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  900 reconstruct mse: 0.003562022 , true mse: None\n",
            "sf: [3. 3.] , iteration:  920 , loss:  tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  940 , loss:  tensor(0.0036, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  950 reconstruct mse: 0.0036625 , true mse: None\n",
            "sf: [3. 3.] , iteration:  960 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  980 , loss:  tensor(0.0039, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1000 , loss:  tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1000 reconstruct mse: 0.0036514327 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1020 , loss:  tensor(0.0036, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1040 , loss:  tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1050 reconstruct mse: 0.003627798 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1060 , loss:  tensor(0.0027, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1080 , loss:  tensor(0.0036, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1100 , loss:  tensor(0.0039, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1100 reconstruct mse: 0.0035877335 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1120 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  3.3441931009292544e-08 STD:  3.1016554400800596e-07\n",
            "learning rate updated:  1e-05\n",
            "sf: [3. 3.] , iteration:  1140 , loss:  tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1150 reconstruct mse: 0.0036108482 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1160 , loss:  tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1180 , loss:  tensor(0.0042, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1200 , loss:  tensor(0.0028, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1200 reconstruct mse: 0.0035792757 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1220 , loss:  tensor(0.0036, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1240 , loss:  tensor(0.0038, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1250 reconstruct mse: 0.003584513 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1260 , loss:  tensor(0.0043, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1280 , loss:  tensor(0.0040, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1300 , loss:  tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1300 reconstruct mse: 0.003573638 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1320 , loss:  tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1340 , loss:  tensor(0.0029, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1350 reconstruct mse: 0.0035454447 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1360 , loss:  tensor(0.0032, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1380 , loss:  tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1400 , loss:  tensor(0.0045, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1400 reconstruct mse: 0.003577845 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1420 , loss:  tensor(0.0041, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -8.385954424738877e-08 STD:  1.016941445830693e-07\n",
            "sf: [3. 3.] , iteration:  1440 , loss:  tensor(0.0039, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1450 reconstruct mse: 0.0035133923 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1460 , loss:  tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1480 , loss:  tensor(0.0039, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "slope:  -2.760686911642525e-07 STD:  1.4508700564104814e-07\n",
            "sf: [3. 3.] , iteration:  1500 , loss:  tensor(0.0037, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1500 reconstruct mse: 0.0035224233 , true mse: None\n",
            "sf: [3. 3.] , iteration:  1520 , loss:  tensor(0.0044, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "sf: [3. 3.] , iteration:  1540 , loss:  tensor(0.0033, device='cuda:0', grad_fn=<MseLossBackward0>)\n",
            "iteration:  1550 reconstruct mse: 0.0035472203 , true mse: None\n",
            "slope:  -1.0374095290899318e-07 STD:  1.7335391514677365e-07\n",
            "learning rate updated:  1.0000000000000002e-06\n",
            "** Done training for sf= [3.0, 3.0]  **\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5eozh58D54PU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}